[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probability Theory for Econometricians",
    "section": "",
    "text": "Welcome\nThis tutorial gives a short introduction to the most important basic concepts of probability theory and statistics for econometricians.\nThis tutorial is still under construction. The two sections presented here are the first two sections of my course Statistics for Data Analytics from Winter Term 2023, which contains a review of probability theory.\nFor a quick review of the basics, I recommend sections 2 and 3 of Stock and Watson (2019): LINK",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "part1_distribution.html",
    "href": "part1_distribution.html",
    "title": "\n1  Distribution\n",
    "section": "",
    "text": "1.1 Random Experiment\nFrom an empirical perspective, a dataset is just a fixed array of numbers. Any summary statistic we compute – like a sample mean, sample correlation, or OLS coefficient – is simply a function of these numbers.\nThese statistics provide a snapshot of the data at hand but do not automatically reveal broader insights about the world. To add deeper meaning to these numbers, identify dependencies, and understand causalities, we must consider how the data were obtained.\nA random experiment is an experiment whose outcome cannot be predicted with certainty. In statistical theory, any dataset is viewed as the result of such a random experiment. While individual outcomes are unpredictable, patterns emerge when experiments are repeated.\nThe gender of the next person you meet, daily fluctuations in stock prices, monthly music streams of your favorite artist, or the annual number of pizzas consumed – all involve a certain amount of randomness and emerge from random experiments. Probability theory gives us the tools to analyze this randomness systematically.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribution</span>"
    ]
  },
  {
    "objectID": "part1_distribution.html#random-experiment-1",
    "href": "part1_distribution.html#random-experiment-1",
    "title": "\n1  Distribution\n",
    "section": "\n1.2 Random experiment",
    "text": "1.2 Random experiment\nFrom an empirical perspective, a dataset is just a fixed array of numbers. Any summary statistic we compute – like a sample mean, sample correlation, or OLS coefficient – is simply a function of these numbers.\nThese statistics provide a snapshot of the data at hand but do not automatically reveal broader insights about the world. To add deeper meaning to these numbers, identify dependencies, and understand causalities, we must consider how the data were obtained.\nA random experiment is an experiment whose outcome cannot be predicted with certainty. In statistical theory, any dataset is viewed as the result of such a random experiment.\nThe gender of the next person you meet, daily fluctuations in stock prices, monthly music streams of your favorite artist, or the annual number of pizzas consumed – all involve a certain amount of randomness and emerge from random experiments.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribution</span>"
    ]
  },
  {
    "objectID": "part1_distribution.html#random-variables",
    "href": "part1_distribution.html#random-variables",
    "title": "\n1  Distribution\n",
    "section": "\n1.2 Random Variables",
    "text": "1.2 Random Variables\nA random variable is a numerical summary of a random experiment. An outcome is a specific result of a random experiment. The sample space S is the set/collection of all potential outcomes.\nLet’s consider some examples:\n\nCoin toss: The outcome of a coin toss can be “heads” or “tails”. This random experiment has a two-element sample space: S = \\{heads, tails\\}. We can express the experiment as a binary random variable: \nY = \\begin{cases}\n1   & \\text{if outcome is heads,} \\\\\n0   & \\text{if outcome is tails.}\n\\end{cases}\n\nGender: If you conduct a survey and interview a random person to ask them about their gender, the answer may be “female”, “male”, or “diverse”. It is a random experiment since the person to be interviewed is selected randomly. The sample space has three elements: S = \\{female, male, diverse\\}. To focus on female vs. non-female, we can define the female dummy variable: \nY = \\begin{cases}\n1   & \\text{if the person is female,} \\\\\n0   & \\text{if the person is not female.}\n\\end{cases}\n Similarly, dummy variables for male and diverse can be defined.\nEducation level: If you ask a random person about their education level according to the ISCED-2011 framework, the outcome may be one of the eight ISCED-2011 levels. We have an eight-element sample space: S = \\{Level \\ 1, Level \\ 2, Level \\ 3, Level \\ 4, Level \\ 5, Level \\ 6, Level \\ 7, Level \\ 8\\}.\n\nThe eight-element sample space of the education-level random experiment provides a natural ordering. We define the random variable education as the number of years of schooling of the interviewed person, with values corresponding to typical completion times in the German education system: \n  Y = \\text{years of schooling} \\in \\{4, 10, 12, 13, 14, 16, 18, 21\\}.\n\n\n\n\nTable 1.1: ISCED 2011 levels\n\n\n\n\nISCED.level\nEducation.level\nYears.of.schooling\n\n\n\n1\nPrimary\n4\n\n\n2\nLower Secondary\n10\n\n\n3\nUpper secondary\n12\n\n\n4\nPost-Secondary\n13\n\n\n5\nShort-Cycle Tertiary\n14\n\n\n6\nBachelor’s\n16\n\n\n7\nMaster’s\n18\n\n\n8\nDoctoral\n21\n\n\n\n\n\n\n\n\n\n\nWage: If you ask a random person about their income per working hour in EUR, there are infinitely many potential answers. Any (non-negative) real number may be an outcome. The sample space is a continuum of different wage levels. The wage level of the interviewed person is already numerical. The random variable is \nY = \\text{income per working hour in EUR}.\n\n\n\nRandom variables share the characteristic that their value is uncertain before conducting a random experiment (e.g., flipping a coin or selecting a random person for an interview). Their value is always a real number and is determined only once the experiment’s outcome is known.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribution</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html",
    "href": "sec02_probability.html",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "2.1 Random experiments\nA random experiment is a procedure or situation where the result is uncertain and determined by a probabilistic mechanism. An outcome is a specific result of a random experiment. The sample space S is the set/collection of all potential outcomes.\nLet’s consider some examples:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#random-experiments",
    "href": "sec02_probability.html#random-experiments",
    "title": "\n2  Probability\n",
    "section": "",
    "text": "Coin toss: The outcome of a coin toss can be ‘heads’ or ‘tails’. This random experiment has a two-element sample space: S = \\{heads, tails\\}.\nGender: If you conduct a survey and interview a random person to ask them about their gender, the answer may be ‘female’, ‘male’, or ‘diverse’. It is a random experiment since the person to be interviewed is selected randomly. The sample space has three elements: S = \\{female, male, diverse\\}.\nEducation level: If you ask a random person about their education level according to the ISCED-2011 framework, the outcome may be one of the eight ISCED-2011 levels. We have an eight-element sample space: S = \\{Level \\ 1, Level \\ 2, Level \\ 3, Level \\ 4, Level \\ 5, Level \\ 6, Level \\ 7, Level \\ 8\\}.\nWage: If you ask a random person about their income per working hour in EUR, there are infinitely many potential answers. Any (non-negative) real number may be an outcome. The sample space is a continuum of different wage levels.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#random-variables",
    "href": "sec02_probability.html#random-variables",
    "title": "\n2  Probability\n",
    "section": "\n2.2 Random variables",
    "text": "2.2 Random variables\nA random variable is a numerical summary of a random experiment. In econometrics and applied statistics, we always express random experiments in terms of random variables. Let’s define some random variables based on the random experiments above:\n\n\nCoin: A two-element sample space random experiment can be transformed to a binary random variable, i.e., a random variable that takes either 0 or 1. We define the coin random variable as \nY = \\begin{cases}\n1   & \\text{if outcome is heads,} \\\\\n0   & \\text{if outcome is tails.}\n\\end{cases}\n A binary random variable is also called Bernoulli random variable.\n\n\n\n\n\n\nFigure 2.1: Bernoulli random variable\n\n\n\nFemale dummy: The three-element sample space of the gender random experiment does not provide any natural ordering. A useful way to transform it into random variables are dummy variables. The female dummy variable is a Bernoulli random variable with \nY = \\begin{cases}\n1   & \\text{if the person is female,} \\\\\n0   & \\text{if the person is not female.}\n\\end{cases}\n Similarly, dummy variables for male and diverse can be defined.\nEducation: The eight-element sample space of the education-level random experiment provides a natural ordering. We define the random variable education as the number of years of schooling of the interviewed person: \nY = \\text{number of years of schooling} \\in \\{4, 10, 12, 13, 14, 16, 18, 21\\}.\n\n\n\n\n\nTable 2.1: ISCED 2011 levels\n\n\n\n\nISCED level\nEducation level\nYears of schooling\n\n\n\n1\nPrimary\n4\n\n\n2\nLower Secondary\n10\n\n\n3\nUpper secondary\n12\n\n\n4\nPost-Secondary\n13\n\n\n5\nShort-Cycle Tertiary\n14\n\n\n6\nBachelor's\n16\n\n\n7\nMaster's\n18\n\n\n8\nDoctoral\n21\n\n\n\n\n\n\n\n\n\n\nWage: The wage level of the interviewed is already numerical. The random variable is \nY = \\text{income per working hour in EUR}.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#probability-function",
    "href": "sec02_probability.html#probability-function",
    "title": "\n2  Probability\n",
    "section": "\n2.3 Probability function",
    "text": "2.3 Probability function\nIn the case of a fair coin, it is natural to assign the following probabilities to the coin variable: P(Y = 0) = 0.5 and P(Y = 1) = 0.5. By definition, the coin variable will never take the value 2.5, so the corresponding probability is P(Y=2.5) = 0. We may also consider intervals, e.g., P(Y \\geq 0) = 1 and P(-1 \\leq Y &lt; 1) = 0.5\nThe probability function P assigns values between 0 and 1 to events. Specific subsets of the real line define events. Any real number defines an event, and any open, half-open, or closed interval represents an event as well, e.g., \n  A_1 = \\{Y=0\\}, \\quad A_2 = \\{Y=1\\}, \\quad A_3 = \\{Y=2.5\\}\n and \n  A_4 = \\{Y \\geq 0\\}, \\quad A_5 = \\{ -1 \\leq Y &lt; 1 \\}.\n We may take complements \n  A_6 := A_4^c = \\{Y \\geq 0\\}^c = \\{ Y &lt; 0\\},\n as well as unions and intersections: \\begin{align*}\nA_7 &:= A_1 \\cup A_6 = \\{Y=0\\} \\cup \\{Y&lt; 0\\} = \\{Y \\leq 0\\}, \\\\\nA_8 &:= A_4 \\cap A_5 = \\{Y \\geq 0\\} \\cap \\{ -1 \\leq Y &lt; 1 \\} = \\{ 0 \\leq Y &lt; 1 \\}.\n\\end{align*} Unions and intersections can also applied iteratively, \n  A_9 := A_1 \\cup A_2 \\cup A_3 \\cup A_5 \\cup A_6 \\cup A_7 \\cup A_8 = \\{ Y \\in (-\\infty, 1] \\cup \\{2.5\\}\\},\n and by taking complements, we obtain the full real line and the empty set: \\begin{align*}\nA_{10} &:= A_9 \\cup A_9^c = \\{Y \\in \\mathbb R\\}, \\\\\nA_{11} &:= A_{10}^c = \\{\\}.\n\\end{align*} You may verify that P(A_1) = 0.5, P(A_2) = 0.5, P(A_3) = 0, P(A_4) = 1 P(A_5) = 0.5, P(A_6) = 0, P(A_7) = 0.5, P(A_8) = 0.5, P(A_9) = 1, P(A_{10}) = 1, P(A_{11}) = 0. If you take the variables education or wage, the probabilities of these events may be completely different.\nTo make probabilities a mathematically sound concept, we have to define to which events probabilities are assigned and how these probabilities are assigned. We consider the concept of a sigma algebra to collect all events.\n\nSigma algebra\nA collection \\mathcal B of sets is called sigma algebra if it satisfies the following three properties:\n\n\\{\\} \\in \\mathcal B  (empty set)\nIf A \\in \\mathcal B then A^c \\in \\mathcal B\nIf A_1, A_2, \\ldots \\in \\mathcal B, then A_1 \\cup A_2 \\cup \\ldots \\in \\mathcal B.\n\n\n\nIf you take all events of the form \\{ Y \\in (a,b) \\}, where a, b \\in \\mathbb R \\cup \\{-\\infty, \\infty\\}, and if you add all unions, intersections, and complements of these events, and again all unions, intersections, and complements of those events, and so on, you will obtain the so-called Borel sigma algebra. The Borel sigma algebra contains all events we assign probabilities to, the Borel sets.\nProbabilities must follow certain conditions. The following axioms ensure that these conditions are fulfilled:\n\nProbability function\nA probability function P is a function P: \\mathcal B \\to [0,1] that satisfies the Axioms of Probability:\n\nP(A) \\geq 0 for every A \\in \\mathcal B\nP(Y \\in \\mathbb R) = 1\nIf A_1, A_2, A_3 \\ldots are disjoint then A_1 \\cup A_2 \\cup A_3 \\cup \\ldots = P(A_1) + P(A_2) + P(A_3) + \\ldots\n\n\n\nRecall that two events A and B are disjoint if they have no outcomes in common, i.e., if A \\cap B = \\{\\}. For instance, A_1 and A_2 are A_1 = \\{Y=0\\} and A_2 = \\{Y=1\\} are disjoint, but A_1 and A_4 = \\{Y \\geq 0\\} are not disjoint, since A_1 \\cap A_4 = \\{Y=0\\} is nonempty.\nProbabilities are a well-defined concept if we use the Borel sigma algebra and the axioms of probability. The mathematical details are developed in the field of measure theory.\nThe axioms of probability imply the following rules of calculation:\n\nBasic rules of probability\n\n\n0 \\leq P(A) \\leq 1  for any event A\n\n\nP(A^c) = 1 - P(A)  for the complement event of A\n\n\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)  for any events A, B (inclusion-exclusion principle)\n\nP(A) \\leq P(B)  if A \\subset B\n\n\nP(A \\cup B) = P(A) + P(B)  if A and B are disjoint",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#distribution",
    "href": "sec02_probability.html#distribution",
    "title": "\n2  Probability\n",
    "section": "\n2.4 Distribution",
    "text": "2.4 Distribution\nThe distribution of a random variable Y is characterized by the probabilities of all events of Y in the Borel sigma algebra. The distribution of the coin variable is fully characterized by the probabilities P(Y=1) = 0.5 and P(Y=0) = 0.5. We can compute the probabilities of all other events using the basic rules of probability. The probability mass function summarizes these probabilities:\n\nProbability mass function (PMF)\nThe probability mass function (PMF) of a random variable Y is \n  \\pi(a) := P(Y = a), \\quad a \\in \\mathbb R\n\n\n\nThe PMF of the coin variable is \n  \\pi(a) = P(Y=a) = \\begin{cases} 0.5 & \\text{if} \\ a \\in\\{0,1\\}, \\\\\n  0 & \\text{otherwise}. \\end{cases}\n The education variable may have the following PMF: \n        \\pi(a) = P(Y=a) = \\begin{cases}\n        0.008 & \\text{if} \\ a = 4 \\\\\n        0.048 & \\text{if} \\ a = 10 \\\\\n        0.392 & \\text{if} \\ a = 12 \\\\\n        0.072 & \\text{if} \\ a = 13 \\\\\n        0.155 & \\text{if} \\ a = 14 \\\\\n        0.071 & \\text{if} \\ a = 16 \\\\\n        0.225 & \\text{if} \\ a = 18 \\\\\n        0.029 & \\text{if} \\ a = 21 \\\\\n        0   & \\text{otherwise}\n        \\end{cases}\n  \nThe PMF is useful for distributions where the sum of the PMF values over a discrete (finite or countably infinite) number of domain points equals 1, as in the examples above. These distributions are called discrete distributions.\nAnother example of a discrete distribution is the Poisson distribution with parameter \\lambda &gt; 0, which has the PMF \n  \\pi(a) = \\begin{cases} \\frac{e^{-\\lambda} \\lambda^a}{a!} & \\text{if} \\ a = 0, 1,2,3, \\ldots \\\\\n  0 & \\text{otherwise.} \\end{cases}\n It has a countably infinite number of domain points with nonzero PMF values, and its probabilities sum to 1, i.e., \\sum_{a=0}^\\infty \\pi(a) = e^{-\\lambda} \\sum_{a=0}^\\infty \\frac{\\lambda^a}{a!} = 1 since the exponential function has the power series representation e^\\lambda = \\sum_{a=0}^\\infty \\frac{\\lambda^a}{a!}.\nNot all random variables are discrete, e.g., the wage variable takes values on a continuum. The cumulative distribution function is a unifying concept summarizing the distribution of any random variable.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#cumulative-distribution-function",
    "href": "sec02_probability.html#cumulative-distribution-function",
    "title": "\n2  Probability\n",
    "section": "\n2.5 Cumulative distribution function",
    "text": "2.5 Cumulative distribution function\n\nCumulative distribution function (CDF)\nThe cumulative distribution function (CDF) of a random variable Y is \n  F(a) := P(Y \\leq a), \\quad a \\in \\mathbb R,\n\n\n\nThe CDF of the variable coin is \n        F(a) = \\begin{cases} 0 & a &lt; 0, \\\\\n        0.5 & 0 \\leq a &lt; 1, \\\\\n        1 & a \\geq 1, \\end{cases}\n     with the following CDF plot:\n\n\n\n\n\nFigure 2.2: CDF of coin\n\n\nThe CDF of the variables education is\n\n\n\n\n\nFigure 2.3: CDF of education\n\n\nand the CDF of the variable wage may have the following form:\n\n\n\n\n\nFigure 2.4: CDF of wage\n\n\nBy the basic rules of probability, we can compute the probability of any event if we know the probabilities of all events of the form \\{Y \\leq a\\}.\n\nSome basic rules for the CDF (for a &lt; b):\n\nP(Y \\leq a) = F(a)\nP(Y &gt; a) = 1 - F(a)\nP(Y &lt; a) = F(a) - \\pi(a)\nP(Y \\geq a) = 1 - P(Y &lt; a)\nP(a &lt; Y \\leq b) = F(b) - F(a)\nP(a &lt; Y &lt; b) = F(b) - F(a) - \\pi(b)\nP(a \\leq Y \\leq b) = F(b) - F(a) + \\pi(a)\nP(a \\leq Y &lt; b) = P(a \\leq Y \\leq b) - \\pi(b)\n\n\n\nSome CDFs have jumps/steps, and some CDFs are smooth/continuous. If F has a jump at domain point a, then the PMF at a is \n  \\pi(a) = P(Y=a) = F(a) - \\lim_{\\epsilon \\to 0} F(a-\\epsilon) = \\text{``jump height at} \\ a\\text{''.}\n\\tag{2.1} If F is continuous at domain point a, we have \\lim_{\\epsilon \\to 0} F(a-\\epsilon) = F(a), which implies that \\pi(a) = P(Y=a) = 0.\nWe call the random variable a discrete random variable if the CDF contains jumps and is flat between the jumps. A discrete random variable has only a finite (or countably infinite) number of potential outcomes. The values of the PMF correspond to the jump heights in the CDF as defined in Equation 2.1. The support \\mathcal Y of a discrete random variable Y is the set of all points a \\in \\mathbb R with nonzero probability mass, i.e. \\mathcal{Y} = \\{ a \\in \\mathbb{R} : \\pi(a) &gt; 0 \\}. The probabilities of a discrete random variable sum to 1, i.e., \\sum_{a \\in \\mathcal Y} \\pi(a)= 1.\nThe Bernoulli variables coin and female are discrete random variables with support \\mathcal Y = \\{0,1\\}. The variable eduaction has support \\mathcal Y = \\{4, 10, 12, 13, 14, 16, 18, 21\\}. A Poisson random variable has thr support \\mathcal Y = \\mathbb N \\cup \\{0\\}.\nWe call a random variable a continuous random variable if the CDF is continuous at every point a \\in \\mathbb R. A continuous random variable has \\pi(a) = P(Y=a) = 0 for all a \\in \\mathbb R. The basic rules for the CDF become simpler in the case of a continuous random variable:\n\nRules for the CDF of a continuous random variable (for a &lt; b):\n\nP(Y \\leq a) = P(Y &lt; a) = F(a)\nP(Y \\geq a) = P(Y &gt; a) = 1 - F(a)\nP(a &lt; Y \\leq b) = P(a \\leq Y &lt; b) = F(b) - F(a)\nP(a &lt; Y &lt; b) = P(a \\leq Y \\leq b) = F(b) - F(a)\n\n\n\nSingle-outcome events are null sets and occur with probability zero. Therefore, the PMF is not suitable to describe the distribution of a continuous random variable. We use the CDF to compute probabilities of interval events as well as their unions, intersections, and complements.\n\n\n\n\n\nFigure 2.5: CDF of wage evaluated at some points\n\n\nFor instance, P(Y \\leq 30) = 0.942, P(Y \\leq 20) = 0.779, P(Y \\leq 10) = 0.217, and P(10 \\leq Y \\leq 20) = 0.779 - 0.217 = 0.562.\n\nQuantiles\nFor a continuous random variable Y the \\alpha-quantile q(\\alpha) is defined as the solution to the equation \\alpha = F(q(\\alpha)), or, equivalently, as the inverse of the distribution function: \n        q(\\alpha) = F^{-1}(\\alpha)\n    \n\n\n\n\nq(\\cdot) is a function from (0,1) to \\mathbb R.\nSome quantiles have special names:\n\nThe median is the 0.5 quantile.\nThe quartiles are the 0.25, 0.5 and 0.75 quantiles.\nThe deciles are the 0.1, 0.2,… , 0.9 quantiles.\n\n\n\n\n\n\n\n\nFigure 2.6: Quantiles of variable wage\n\n\nFrom the quantile plot, we find that q(0.1) = 7.73, q(0.5) = 13.90, q(0.9) = 26.18. Under this wage distribution, the median wage is 13.90 EUR, the poorest 10% have a wage of less than 7.33 EUR, and the richest 10% have a wage of more than 26.18 EUR.\n\n\n\n\n\nFigure 2.7: Quantiles of variable education\n\n\nThe median of education is 13, the 0.1-quantile is 12, and the 0.9-quantile is 18.\nA CDF has the following properties:\n\nit is non-decreasing,\nit is right-continuous (jumps may occur only when the limit point is approached from the left)\nthe left limit is zero: \\lim_{a \\to -\\infty} F(a) = 0\n\nthe right limit is one: \\lim_{a \\to \\infty} F(a) = 1.\n\nAny function F that satisfies these four properties defines a probability distribution. Typically, distributions are divided into discrete and continuous distributions. Still, it may be the case that a distribution does not fall into either of these categories (for instance, if a CDF has jumps on some domain points and is continuously increasing on other domain intervals). In any case, the CDF characterizes the entire distribution of any random variable.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#probability-density-function",
    "href": "sec02_probability.html#probability-density-function",
    "title": "\n2  Probability\n",
    "section": "\n2.6 Probability density function",
    "text": "2.6 Probability density function\nFor discrete random variables, both the PMF and the CDF characterize the distribution. In the case of a continuous random variable, the PMF does not yield any information about the distribution since it is zero. The continuous counterpart of the PMF is the density function:\n\nProbability density function\nThe probability density function (PDF) or simply density function of a continuous random variable Y is a function f(a) that satisfies \n    F(a) = \\int_{-\\infty}^a f(u) \\ \\text{d}u\n The density f(a) is the derivative of the CDF F(a) if it is differentiable: \n    f(a) = \\frac{d}{da} F(a).\n\n\n\nProperties of a PDF:\n\nf(a) \\geq 0 for all a \\in \\mathbb R\n\\int_{-\\infty}^\\infty f(u) \\ \\text{d}u = 1\n\n\n\n\n\n\nFigure 2.8: PDF of the variable wage\n\n\n\nProbability rule for the PDF: \n  P(a &lt; Y &lt; b) = \\int_a^b f(u) \\ \\text{d} u = F(b) - F(a)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#expected-value",
    "href": "sec02_probability.html#expected-value",
    "title": "\n2  Probability\n",
    "section": "\n2.7 Expected value",
    "text": "2.7 Expected value\nThe expectation or expected value is the most important measure of the central tendency of a distribution. It gives you the average value you can expect to get if you repeat the random experiment multiple times. We define the expectation first for discrete random variables, then continuous random variables, and finally give a unified definition for all random variables.\n\n2.7.1 Expectation of a discrete random variable\n\nThe expectation or expected value of a discrete random variable Y with PMF \\pi(\\cdot) and support \\mathcal Y is defined as \n    E[Y] =\n    \\sum_{u \\in \\mathcal Y} u \\pi(u).\n\n\nFor the coin variable, we have \\mathcal Y = \\{0,1\\} and therefore \n  E[Y] = 0\\cdot\\pi(0) + 1\\cdot\\pi(1) = 0.5.\n For the variable education we get \\begin{align*}\n  E[Y] &= 4\\cdot\\pi(4) + 10\\cdot\\pi(10) + 12\\cdot \\pi(12) \\\\\n  &\\phantom{=} + 13\\cdot\\pi(13) + 14\\cdot\\pi(14) + 16\\cdot \\pi(16) \\\\\n  &\\phantom{=} + 18 \\cdot \\pi(18) + 21*\\pi(21) = 13.557\n\\end{align*}\nThe expectation of a Poisson distributed random variable Y with parameter \\lambda is \n  E[Y] = 0+ \\sum_{a=1}^\\infty a \\cdot e^{-\\lambda}\\frac{\\lambda^a}{a!} =\ne^{-\\lambda} \\sum_{a=1}^\\infty \\frac{\\lambda^a}{(a-1)!} = e^{-\\lambda} \\sum_{a=0}^\\infty \\frac{\\lambda^{a+1}}{a!} = \\lambda e^{-\\lambda} e^{\\lambda} = \\lambda.\n\n\n2.7.2 Expectation of a continuous random variable\n\nThe expectation or expected value of a of a continuous random variable Y with PDF f(\\cdot) is \n    E[Y] =\n    \\int_{-\\infty}^\\infty u f(u) \\ \\text{d}u.\n\n\nUsing numerical integration for the density of Figure 6.2 yields the expected value of 16.45 EUR for the wage variable, which is larger than the median value of 13.90 EUR. If the mean is larger than the median, we have a positively skewed distribution, meaning that a few people have high salaries, and many people have medium and low wages.\nThe uniform distribution on the unit interval [0,1] has the PDF \n  f(u) = \\begin{cases} 1 & \\text{if} \\ u \\in[0,1], \\\\ 0 & \\text{otherwise,} \\end{cases}\n and the expected value of a uniformly distributed random variable Y is \n  E[Y] = \\int_{-\\infty}^\\infty u f(u) \\ \\text{d} u = \\int_{0}^1 u \\ \\text{d} u = \\frac{1}{2}.\n\n\n2.7.3 Expectation for general random variables\nWe can also define the expected value in a unified way for any random variable so we do not have to distinguish between discrete and continuous random variables. Let F(\\cdot) be the CDF of the random variable of interest and consider the differential \\text{d} F(u), which corresponds to an infinitesimal change in F(\\cdot) at u. For a discrete random variable, F(u) changes only if there is a step/jump at u and zero otherwise because it is flat. Thus, for a discrete distribution, \n  \\text{d} F(u) = \\begin{cases} \\pi(u) & \\text{if} \\ u \\in \\mathcal Y \\\\\n  0 & \\text{if} \\ u \\notin \\mathcal Y. \\end{cases}\n In the case of a continuous random variable with differentiable CDF F(\\cdot), we have \n  \\text{d} F(u) = f(u) \\ \\text{d}u,\n where f(\\cdot) is the PDF of the random variable. This gives rise to the following unified definition of the expected value:\n\nThe expectation or expected value of any random variable with CDF F(\\cdot) is defined as \n  E[Y] =\n    \\int_{-\\infty}^\\infty u \\ \\text{d}F(u).\n\\tag{2.2}\n\n\nNote that Equation 2.2 is the Riemann-Stieltjes integral of a with respect to the function F(\\cdot). Recall that the Riemann integral of u with respect to u over the interval [-1,1] is \\int_{-1}^1 u \\ \\text{d} u := \\lim_{N\\to \\infty} \\sum_{j=1}^{2N} \\Big(\\frac{j}{N} - 1\\Big) \\Big(\\big(\\tfrac{j}{N} - 1\\big) - \\big(\\tfrac{j-1}{N} - 1 \\big)\\Big) = \\lim_{N\\to \\infty} \\sum_{j=1}^{2N} \\Big(\\frac{j}{N} - 1\\Big) \\frac{1}{N}, for the interval [-z,z] we have \\int_{-z}^z u \\ \\text{d} u := \\lim_{N\\to \\infty} \\sum_{j=1}^{2N} z\\Big(\\frac{j}{N} - 1\\Big) \\frac{z}{N}, and we obtain \\int_{-\\infty}^\\infty u \\ \\text{d} u := \\lim_{z \\to \\infty} \\int_{-z}^z u \\ \\text{d} u for the integral over the entire real line. Note that z/N = z(\\frac{j}{N}-1) - z(\\frac{j-1}{N}-1) corresponds to a change in u on [-z,z] so we approximate \n\\text{d} u \\approx z\\big(\\tfrac{j}{N}-1\\big) - z\\big(\\tfrac{j-1}{N}-1\\big) = \\tfrac{z}{N}\n and let N tend to infinity. In the case of the Riemann-Stieltjes integral, where we integrate with respect to changes in a function F(\\cdot), i.e., \\text{d} F(u). In an interval [-z,z], we have \\text{d} F(u) \\approx F\\Big(z\\big(\\tfrac{j}{N}-1\\big)\\Big) - F\\Big(z\\big(\\tfrac{j-1}{N}-1\\big)\\Big), and we define \\begin{align*}\n  \\int_{-z}^z u \\ \\text{d}F(u) &:= \\lim_{N \\to \\infty} \\sum_{j=1}^{2N} z\\Big(\\tfrac{j}{N} - 1\\Big) F\\Big(z\\big(\\tfrac{j}{N}-1\\big)\\Big) - F\\Big(z\\big(\\tfrac{j-1}{N}-1\\big)\\Big) \\\\\n  \\int_{-\\infty}^\\infty u \\ \\text{d}F(u) &:= \\lim_{z\\to \\infty} \\int_{-z}^z u \\ \\text{d}F(u)\n\\end{align*}\n\n2.7.4 Properties of the expected value\nThe expected value is a measure of central tendency. It is a linear function. For any two random variables Y and Z and any a,b \\in \\mathbb R, we have \n  E[aY + bZ] = a E[Y] + b E[Z].\n\nThe expected value has some optimality properties in terms of prediction. The best predictor of a random variable Y in the mean square error sense is the value g^* that minimizes E[(Y-g)^2] over g. We have \n  E[(Y-g)^2] = E[Y^2] -2gE[Y] + g^2,\n and minimizing over g yields \n  \\frac{\\text{d}E[(Y-g)^2]}{\\text{d}g} = -2E[Y] + 2g,\n which is zero if g=E[Y]. The second derivative is positive. Therefore, the expected value is the best predictor for a random variable if you do not have any further information available.\nWe often transform random variables by taking, for instance, squares Y^2 or logs \\log(Y). For any transformation function g(\\cdot), the expectation of the transformed random variable g(Y) is \n  E[g(Y)] = \\int_{-\\infty}^\\infty g(u) \\ \\text{d}F(u),\n where \\text{d}F(u) can be replaced by the PMF or the PDF as discussed in Section 2.7.3 for the different cases. For instance, if we take the coin variable Y and consider the transformed random variable \\log(Y+1), the expected value is \n  E[\\log(Y+1)] = \\log(1) \\cdot \\frac{1}{2} + \\log(2) \\cdot \\frac{1}{2} = \\frac{\\log(2)}{2}\n\n\nMoments\nThe r-th moment of a random variable Y is defined as \n    E[Y^r] = \\int_{-\\infty}^\\infty u^r \\ \\text{d}F(u) = \\begin{cases}\n      \\sum_{u \\in \\mathcal Y} u^r \\pi(u) & \\text{if} \\ Y \\ \\text{is discrete,} \\\\\n      \\int_{-\\infty}^\\infty u^r f(u)\\text{d}u & \\text{if} \\ Y \\ \\text{is continuous.} \\end{cases}",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#descriptive-features-of-a-distribution",
    "href": "sec02_probability.html#descriptive-features-of-a-distribution",
    "title": "\n2  Probability\n",
    "section": "\n2.8 Descriptive features of a distribution",
    "text": "2.8 Descriptive features of a distribution\n\nSome important features of the distribution of Y\n\n\n\n\n\n\n\n\nE[Y^r]\n\nr-th moment of Y\n\n\n\n\nE[(Y-E[Y])^r]\n\nr-th central moment of Y\n\n\n\n\nVar[Y] = E[(Y-E[Y])^2]\n\nvariance of Y\n\n\n\n\nsd(Y) = \\sqrt{Var[Y]}\n\nstandard deviation of Y\n\n\n\n\nE[((Y-E[Y])/sd(Y))^r]\n\nr-th standardized moment of Y\n\n\n\nskew = E[((Y-E[Y])/sd(Y))^3]\n\nskewness of Y\n\n\n\nkurt = E[((Y-E[Y])/sd(Y))^4]\n\nkurtosis of Y\n\n\n\n\nThe mean is a measure of central tendency and equals the expected value. The variance and standard deviation are measures of dispersion. We have \n  Var[Y] = E[(Y-E[Y])^2] = E[Y^2] - E[Y]^2\n and \n  Var[a+bY] = b^2 Var[Y]\n for any a,b \\in \\mathbb R. The skewness \n  skew = \\frac{E[(Y - E[Y])^3]}{sd(Y)^3} =\\frac{E[Y^3] - 3 E[Y^2] E[Y] + 2 E[Y]^3}{(E[Y^2] - E[Y]^2)^{3/2}}\n is a measure of asymmetry\n\n\n\n\n\nFigure 2.9: Positive and negative skewness\n\n\nA random variable Y has a symmetric distribution about 0 if F(u) = 1 - F(-u). If Y has a density, it is symmetric if f(x) = f(-x). If Y is symmetric about 0, then the skewness is 0. The skewness of the variable wage (see Figure 6.2) is positive, i.e., the distribution is positively skewed. The standard normal distribution \\mathcal N(0,1) , which has the density \n  f(u) = \\phi(u) = \\frac{1}{\\sqrt{2\\pi}} e^{-u^2/2}.\n\nBelow you find a plot of the PDFs of N(0,1) together with the t_5-distribution, which is the t-distribution with 5 degrees of freedom:\n\n\n\n\n\nFigure 2.10: PDFs of the standard normal distribution (solid) and the t_5-distribution (dashed)\n\n\nThe standard normal distribution and the t(5) distribution have skewness 0. The kurtosis \n  kurt = \\frac{E[(Y - E[Y])^4]}{sd(Y)^4} =\\frac{E[Y^4] - 4 E[Y^3] E[Y] + 6 E[Y^2]E[Y]^2 - 3 E[Y]^4 }{(E[Y^2] - E[Y]^2)^2}\n is a measure of how likely extreme outliers are. The standard normal distribution has kurtosis 3 and the t(5) distribution has kurtosis 9 so that outliers in t(5) are more likely than in \\mathcal N(0,1):\n\npar(mfrow=c(1,2), cex.main=1)\nplot(rnorm(1000), main = \"1000 simulated values of N(0,1)\", ylab = \"\")\nplot(rt(1000,5), main = \"1000 simulated values of t(5)\", ylab = \"\")\n\n\n\n\n\n\n\nThe kurtosis of the variable wage is also larger than 3, meaning outliers are much more likely than in the standard normal distribution. In this case, the positive skewness means that more people have a wage less than the average, and the large kurtosis means that there are very few people with exceptionally high salaries (outliers).\nAll features discussed above are functions of the first four moments E[Y], E[Y^2], E[Y^3] and E[Y^4].\n\n2.8.1 Heavy-tailed distributions\nExpectations might be infinity. For instance, the simple Pareto distribution has the PDF \n  f(a) = \\begin{cases} \\frac{1}{a^2} & \\text{if} \\ a &gt; 1, \\\\\n  0 & \\text{if} \\ a \\leq 1, \\end{cases}\n and the expected value is \n  E[X] = \\int_{-\\infty}^\\infty a f(a) \\ \\text{d}a\n  = \\int_{1}^\\infty  \\frac{1}{a} \\ \\text{d}a = \\log(a)|_1^\\infty = \\infty.\n The game of chance from the St. Petersburg paradox (see https://en.wikipedia.org/wiki/St._Petersburg_paradox) is an example of a discrete random variable with infinite expectation.\nThere are distributions with finite mean with some higher moments that are infinite. For instance, the first m-1 moments of the t_m distribution (Student’s-t distribution with m degrees of freedom) are finite, but the m-th moment and all higher order moments are infinite. Random variables with infinite first four moments have a so-called heavy-tailed distribution and may produce huge outliers. Many statistical procedures are only valid if the underlying distribution is not heavy-tailed.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#the-normal-distribution",
    "href": "sec02_probability.html#the-normal-distribution",
    "title": "\n2  Probability\n",
    "section": "\n2.9 The normal distribution",
    "text": "2.9 The normal distribution\nA random variable X is normally distributed with parameters (\\mu, \\sigma^2) if it has the density \n    f(a \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\Big( - \\frac{(a- \\mu)^2}{2 \\sigma^2} \\Big).\n   We write Y \\sim \\mathcal N(\\mu, \\sigma^2). Mean and variance are \n        E[Y] = \\mu, \\quad var[Y] = \\sigma^2.\n     Special case: standard normal distribution \\mathcal{N}(0,1) with density \n    \\phi(a) = \\frac{1}{\\sqrt{2 \\pi}} \\exp\\Big( - \\frac{a^2}{2} \\Big)\n   and CDF \n    \\Phi(a) = \\int_{-\\infty}^a \\phi(u)\\text{d}u.\n   \\mathcal N(0,1) is symmetric around zero: \n    \\phi(a) = \\phi(-a), \\quad \\Phi(a) = 1 - \\Phi(-a)\n\n\npar(mfrow=c(1,2), bty=\"n\", lwd=1)\nx &lt;- seq(-5,9,by=0.01)\nplot(x,dnorm(x,2,2),ylab=\"\",xlab=\"\", type=\"l\", main= \"PDF of N(2,2)\")\nplot(x,pnorm(x,2,2),ylab=\"\",xlab=\"\", type=\"l\", main = \"CDF of N(2,2)\")\n\n\n\n\n\n\n\nIf Y_1, \\ldots, Y_n are normally distributed and c_1, \\ldots, c_n \\in \\mathbb R, then \\sum_{j=1}^n c_j Y_j is normally distributed.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#additional-reading",
    "href": "sec02_probability.html#additional-reading",
    "title": "\n2  Probability\n",
    "section": "\n2.10 Additional reading",
    "text": "2.10 Additional reading\n\nStock and Watson (2019), Section 2\nHansen (2022a), Section 1-2\nDavidson and MacKinnon (2004), Section 1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec02_probability.html#r-codes",
    "href": "sec02_probability.html#r-codes",
    "title": "\n2  Probability\n",
    "section": "\n2.11 R-codes",
    "text": "2.11 R-codes\nstatistics-sec2.R",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html",
    "href": "sec03_dependence.html",
    "title": "\n3  Dependence\n",
    "section": "",
    "text": "3.1 Multivariate random variables\nIn statistics, we typically study multiple random variables simultaneously. We can collect k random variable X_1, \\ldots, X_k in a random vector \n      X = \\begin{pmatrix}\n      X_1 \\\\ \\vdots \\\\ X_k\n    \\end{pmatrix}=   (X_1, \\ldots, X_k)'.\n   We also call X a k-variate random variable.\nSince X is a random vector, its outcome is also vector-valued, e.g. X = x \\in \\mathbb R^k with x=(x_1, \\ldots, x_k)'. Events of the form \\{X \\leq x\\} mean that each component of the random vector X is smaller than the corresponding values of the vector x, i.e. \n\\{X \\leq x\\} = \\{X_1 \\leq x_1, \\ldots, X_k \\leq x_k\\}.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#bivariate-random-variables",
    "href": "sec03_dependence.html#bivariate-random-variables",
    "title": "\n3  Dependence\n",
    "section": "\n3.2 Bivariate random variables",
    "text": "3.2 Bivariate random variables\nIf k = 2, we call X a bivariate random variable. Consider, for instance, the coin toss Bernoulli variable Y with P(Y=1) = 0.5 and P(Y=0) = 0.5, and let Z be a second coin toss with the same probabilities. X = (Y,Z) is a bivariate random variable where both entries are discrete random variables. Since the two coin tosses are performed separately from each other, it is reasonable to assume that the probability that the first and second coin tosses show ‘heads’ is 0.25, i.e., P(\\{Y=1\\} \\cap \\{Z=1\\}) = 0.25. We would expect the following joint probabilities:\n\n\nTable 3.1: Joint probabilities of coin tosses\n\n\n\n\n\n\n\n\n\n\n\nZ=1\nZ=0\nany result\n\n\nY=1\n0.25\n0.25\n0.5\n\n\nY=0\n0.25\n0.25\n0.5\n\n\nany result\n0.5\n0.5\n1\n\n\n\n\n\n\nThe probabilities in the above table characterize the joint distribution of Y and Z. The table shows the values of the joint probability mass function: \n  \\pi_{YZ}(a,b) = \\begin{cases} 0.25 & \\text{if} \\ a \\in \\{0,1\\} \\ \\text{and} \\ b \\in \\{0,1\\} \\\\\n  0 & \\text{otherwise} \\end{cases}\n Another example are the random variables Y, a dummy variable for the event that the person has a high wage (more than 25 USD/hour), and Z, a dummy variable for the event that the same person has a university degree. Similarly, X = (Y,Z) is a bivariate random variable consisting of two univariate Bernoulli variables. The joint probabilities might be as follows:\n\n\nTable 3.2: Joint probabilities of wage and education dummies\n\n\n\n\n\n\n\n\n\n\n\nZ=1\nZ=0\nany education\n\n\nY=1\n0.19\n0.12\n0.31\n\n\nY=0\n0.17\n0.52\n0.69\n\n\nany wage\n0.36\n0.64\n1\n\n\n\n\n\n\nThe joint probability mass function is \n  \\pi_{YZ}(a,b) = \\begin{cases}\n      0.19 & \\text{if} \\ a=1, b=1, \\\\\n      0.12 & \\text{if} \\ a=1, b=0, \\\\\n      0.17 & \\text{if} \\ a=0, b=1, \\\\\n      0.52 & \\text{if} \\ a=0, b=0, \\\\\n      0   & \\text{otherwise.}\n  \\end{cases}\n The marginal probability mass function of Y is \\begin{align*}\n  \\pi_Y(a) &= P(Y=a) = \\pi_{YZ}(a,0) + \\pi_{YZ}(a,1) \\\\\n  &= \\begin{cases}\n  0.19 + 0.12 = 0.31 & \\text{if} \\ a = 1, \\\\\n  0.17 + 0.52 = 0.69 & \\text{if} \\ a = 0, \\\\\n  0 & \\text{otherwise.}\n  \\end{cases}\n\\end{align*} and the marginal probability mass function of Z is \\begin{align*}\n  \\pi_Z(b) &= P(Z=b) = \\pi_{YZ}(0,b) + \\pi_{YZ}(1,b) \\\\\n  &= \\begin{cases}\n  0.19 + 0.17 = 0.36 & \\text{if} \\ b = 1, \\\\\n  0.12 + 0.52 = 0.64 & \\text{if} \\ b = 0, \\\\\n  0 & \\text{otherwise.}\n  \\end{cases}\n\\end{align*}\nAn example of a continuous bivariate random variable is X = (Y,Z), where Y is the wage level in EUR/hour and Z is the labor market experience of the same person measured in years.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#bivariate-distributions",
    "href": "sec03_dependence.html#bivariate-distributions",
    "title": "\n3  Dependence\n",
    "section": "\n3.3 Bivariate distributions",
    "text": "3.3 Bivariate distributions\n\nBivariate distribution\nThe joint distribution function of a bivariate random variable (Y,Z) is\nF_{YZ}(a, b) = P(Y \\leq a, Z \\leq b) = P(\\{Y \\leq a\\} \\cap \\{ Z \\leq b\\}).\n\n\n\n\n\n\nFigure 3.1: Joint CDF of wage and experience\n\n\nCalculation of probabilities using a bivariate distribution function: \\begin{align*}\n        P(Y \\leq a, Z \\leq b) &= F_{YZ}(a,b) \\\\\n        P(a &lt; Y \\leq b, c &lt; Z \\leq d) &= F_{YZ}(b,d) - F_{YZ}(b,c) - F_{YZ}(a,d) + F_{YZ}(a,c)\n\\end{align*}\n\n\n\n\n\nFigure 3.2: Calculate probabilities using the joint CDF\n\n\n\n\n\n\n\nFigure 3.3: Calculate probabilities using the joint CDF\n\n\n\nMarginal distributions\nThe marginal distributions of Y and Z are \\begin{align*}\n        F_Y(a) = P(Y \\leq a) &= P(Y \\leq a, Z &lt; \\infty) &= \\lim_{b \\to \\infty} F_{YZ}(a,b),\\\\\n        F_Z(b) = P(Z \\leq b) &= P(Y &lt; \\infty, Z \\leq b) &= \\lim_{a \\to \\infty} F_{YZ}(a,b)\n\\end{align*}\n\n\n\n\n\n\n\nFigure 3.4: Marginal CDF of experience\n\n\n\n\n\n\n\nFigure 3.5: Marginal CDF of wage\n\n\n\nBivariate density function\nThe joint density function of a bivariate continuous random variable (Y,Z) with differentiable joint CDF F_{YZ}(a,b) equals \n    f_{YZ}(a,b) = \\frac{\\partial^2}{\\partial a \\partial b} F_{YZ}(a,b).\n\n\n\nThe marginal densities of Y and Z are \\begin{align*}\nf_Y(a) &= \\frac{d}{d a} F_Y(a) = \\int_{-\\infty}^\\infty f_{YZ}(a,b)\\text{d}b, \\\\\nf_Z(b) &= \\frac{d}{d b} F_Z(b) =        \\int_{-\\infty}^\\infty f_{YZ}(a,b)\\text{d}a.\n\\end{align*}\n\n\n\n\n\nFigure 3.6: Joint CDF of wage and experience\n\n\n\n\n\n\n\nFigure 3.7: Joint PDF of wage and experience",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#correlation",
    "href": "sec03_dependence.html#correlation",
    "title": "\n3  Dependence\n",
    "section": "\n3.4 Correlation",
    "text": "3.4 Correlation\nConsider the bivariate continuous random variable (Y,Z) with joint density f_{YZ}(a,b). The expected value of g(Y,Z), where g(\\cdot, \\cdot) is any real-valued function, is given by \n  E[g(X,Y)] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty g(a,b) f_{YZ}(a,b) \\ \\text{d}a \\ \\text{d}b.\n\nThe first cross moment of Y and Z is E[YZ]. We have E[YZ] = E[g(Y,Z)] for the function g(Y,Z) = Y\\cdot Z. Therefore, \n      E[YZ] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty ab f_{YZ}(a,b) \\ \\text{d}a \\ \\text{d}b.\n   The covariance of Y and Z is defined as\n   Cov(Y,Z) = E[(Y- E[Y])(Z-E[Z])] = E[YZ] - E[Y]E[Z].\n The covariance of Y and Y is the variance: \n  Cov(Y,Y) = Var[Y].\n The variance of the sum of two random variables depends on the covariance: \n  Var[Y+Z] = Var[Y] + 2 Cov(Y,Z) + Var[Z]\n The correlation of Y and Z is \n  Corr(Y,Z) = \\frac{Cov(Y,Z)}{sd(Y) sd(Z)}\n\n\nUncorrelated\nY and Z are uncorrelated if Corr(Y,Z) = 0, or, equivalently, if Cov(Y,Z) = 0.\n\n\nIf Y and Z are uncorrelated, we have \\begin{align*}\n        E[YZ] &= E[Y] E[Z] \\\\\n        var[Y+Z] &= var[Y] + var[Z]\n\\end{align*}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#independence",
    "href": "sec03_dependence.html#independence",
    "title": "\n3  Dependence\n",
    "section": "\n3.5 Independence",
    "text": "3.5 Independence\nTwo events A and B are independent if \n        P[A \\cap B] = P[A] P[B].\n For instance, in the bivariate random variable of Table 3.1 (two coin tosses), we have P(Y=1, Z=1) = 0.25 = 0.5 \\cdot 0.5 = P(Y=1)P(Z=1). Hence, \\{Y=1\\} and \\{Z=1\\} are independent events. In the bivariate random variable of Table 3.2 (wage/education), we find P(Y=1, Z=1) = 0.19 \\neq P(Y=1)P(Z=1) = 0.31 \\cdot 0.36 = 0.1116. Therefore, the two events are not independent. In this case, the two random variables are dependent.\n\nIndependence\nY and Z are independent random variables if, for all a and b, the bivariate distribution function is the product of the marginal distribution functions: \n        F_{YZ}(a,b) = F_Y(a) F_Z(b).\n     If this property is not satisfied, we say that X and Y are dependent.\n\n\nThe random variables Y and Z of Table 3.1 are independent, and those of Table 3.2 are dependent.\nIf Y and Z are independent and have finite second moments, then Y and Z are uncorrelated. The reverse is not true!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#random-vectors",
    "href": "sec03_dependence.html#random-vectors",
    "title": "\n3  Dependence\n",
    "section": "\n3.6 Random vectors",
    "text": "3.6 Random vectors\nThe above concepts can be generalized to any k-variate random vector X = (X_1, \\ldots, X_k). The joint CDF of X is \n    F_X(x) = P(X_1 \\leq x_1, \\ldots, X_k \\leq x_k).\n X has independent entries if \n        F_X(x) = \\prod_{i=1}^k P(X_i \\leq x_i) = \\prod_{i=1}^k F_{X_i}(x_i)\n     If F_X(x) is a continuous CDF, the joint k-dimensional density is \n    f_X(x) = f_X(x_1, \\ldots, x_k) = \\frac{\\partial^k}{\\partial x_1 \\cdots \\partial x_k} F_X(x_1, \\ldots ,x_k).\n  \nThe expectation vector of X is \n        E[X] = \\begin{pmatrix} E[X_1] \\\\  \\vdots \\\\ E[X_k] \\end{pmatrix},\n     and the covariance matrix of X is \\begin{align*}\nVar[X] &= E[(X-E[X])(X-E[X])'] \\\\\n      &= \\begin{pmatrix}\n            Var[X_1] & Cov(X_1, X_2) & \\ldots & Cov(X_1, X_k) \\\\\n            Cov(X_2, X_1) & Var[X_2] & \\ldots & Cov(X_2, X_k) \\\\\n            \\vdots & \\vdots & \\ddots & \\vdots \\\\\n            Cov(X_k, X_1) & Cov(X_k, X_2) & \\ldots & Var[X_k]\n        \\end{pmatrix}\n\\end{align*}\nFor any random vector X, the covariance matrix Var[X] is symmetric and positive semi-definite.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#conditional-distributions",
    "href": "sec03_dependence.html#conditional-distributions",
    "title": "\n3  Dependence\n",
    "section": "\n3.7 Conditional distributions",
    "text": "3.7 Conditional distributions\n\nConditional probability\nThe conditional probability of an event A given an event B with P(B) &gt; 0 is \n  P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}\n\n\n\nLet’s revisit the wage and schooling example from Table 3.2: \n     P(Y=1 \\mid Z=1) = \\frac{P(\\{Y=1\\}\\cap \\{Z=1\\})}{P(Z=1)} = \\frac{0.19}{0.36} = 0.53\n     \n     P(Y=1 \\mid Z=0) = \\frac{P(\\{Y=1\\}\\cap \\{Z=0\\})}{P(Z=0)} = \\frac{0.12}{0.64} = 0.19\n    \nNote that \nP(Y=1 \\mid Z=1) = 0.53 &gt; 0.31 = P(Y=1)\n implies \nP(\\{Y=1\\}\\cap \\{Z=1\\}) &gt; P(Y=1) \\cdot P(Z=1).\n If P(A \\mid B) = P(A), then the events A and B are independent. If P(A \\mid B) \\neq P(A), they are dependent.\n\nConditional distribution of continuous variables\nConsider the density f_{YZ}(a,b) of two continuous random variables Y and Z. The conditional density of Y given Z=b is \n        f_{Y|Z}(a \\mid b) = \\frac{f_{YZ}(a,b)}{f_Z(b)}.\n The conditional distribution of Y given Z=b is \n    F_{Y|Z}(a \\mid b)  = \\int_0^a f_{Y|Z}(u \\mid b) \\ \\text{d}u.\n\n\n\n\n\n\n\n\nFigure 3.8: Joint PDF of wage and experience\n\n\n\n\n\n\n\nFigure 3.9: Conditional PDFs of wage given experience\n\n\n\n\n\n\n\nFigure 3.10: PDF of variable experience\n\n\nIf Y is continuous and Z is discrete, the conditional distribution function of Y given \\{Z=b\\} with P(Z=b) &gt; 0 is \n      F_{Y|Z}(a \\mid b) = P(Y \\leq a \\mid Z=b) = \\frac{P(Y \\leq a, Z=b)}{P(Z=b)}.\n  \nIf F_{Y|Z}(a \\mid b) is differentiable with respect to b, the conditional density of Y given Z=b is \n        f_{Y|Z}(a \\mid b) = \\frac{\\partial}{\\partial a} F_{Y|Z}(a \\mid b).\n    \n\n\n\n\n\nFigure 3.11: Conditional CDFs of wage given education\n\n\n\n\n\n\n\nFigure 3.12: Conditional PDFs of wage given education\n\n\nWe often are interested in conditioning on multiple variables, such as the wage given a particular education and experience level. Let f(y,x) = f(y,x_1, \\ldots, x_k) be the joint density of the composite random vector (Y, X_1, \\ldots, X_k) with X = (X_1, \\ldots, X_k). The conditional density of a random variable Y given X = x = (x_1, \\ldots, x_k)' is \n        f_{Y|X}(y \\mid x) = f(y \\mid x_1, \\ldots, x_k) = \\frac{f(y, x_1, \\ldots, x_k)}{f_X(x_1, \\ldots, x_k)} = \\frac{f(y,x)}{f_X(x)}\n     The conditional distribution of Y given X=x is \n        F_{Y|X}(y\\mid x) = \\int_0^y f(u \\mid x)\\ \\text{d}u.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#conditional-expectation",
    "href": "sec03_dependence.html#conditional-expectation",
    "title": "\n3  Dependence\n",
    "section": "\n3.8 Conditional expectation",
    "text": "3.8 Conditional expectation\n\nConditional expectation function\nThe conditional expectation of Y given X=x is the expected value of the distribution F_{Y|X}(y \\mid x). For continuous Y with conditional density f_{Y|X}(y \\mid x), the conditional expectation is\n\n    E[Y \\mid X=x] = \\int_{-\\infty}^\\infty y f_{Y|X}(y \\mid x)\\ \\text{d}y.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) CEF wage given experience\n\n\n\n\n\n\n\n\n\n(b) CEF wage given education\n\n\n\n\n\n\nFigure 3.13: Conditional expectation functions\n\n\nConsider again the wage and experience example. Suppose that the conditional expectation has the functional form \n    E[wage \\mid experience = x ] = m(x) = 14.5 + 0.9 x - 0.017 x^2.\n E.g., for x=10 we have E[wage \\mid experience = 10] = m(10) = 21.8.\nNote that m(x) = E[wage \\mid experience = x] is not random. It is a feature of the joint distribution.\nSometimes, it is useful not to fix the experience level to a certain value but to treat it as random:\n\\begin{align*}\n      E[wage \\mid experience] &= m(experience) \\\\\n      &= 14.5 + 0.9 experience - 0.017 experience^2\n\\end{align*}\nm(experience) = E[wage \\mid experience] is a function of the random variable experience and, therefore, itself a random variable.\nThe conditional expectation function (CEF) of Y given the specific event \\{X=x\\} is \n      m(x) = E[Y \\mid X=x].\n   m(x) is deterministic (non-random) and a feature of the joint distribution.\nThe conditional expectation function (CEF) of Y given the random vector X is \n      m(X) = E[Y \\mid X].\n   m(X) is a function of the random vector X and therefore itself a random variable.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#law-of-iterated-expectations",
    "href": "sec03_dependence.html#law-of-iterated-expectations",
    "title": "\n3  Dependence\n",
    "section": "\n3.9 Law of iterated expectations",
    "text": "3.9 Law of iterated expectations\n\nRules of calculation for the conditional expectation \nLet Y be a random variable and X a random vector.\n\nLaw of the iterated expectations (LIE): \nE[E[Y \\mid X]] = E[Y].\n   A more general LIE: For any two random vectors X and \\widetilde X, \n  E[E[Y \\mid X, \\widetilde X] \\mid X] = E[Y \\mid X].\n  \nConditioning theorem (CT): For any function g(\\cdot), \nE[g(X) Y \\mid X] = g(X) E[Y \\mid X].\n  \nIf Y and X are independent then E[Y \\mid X] = E[Y].",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#conditional-variance",
    "href": "sec03_dependence.html#conditional-variance",
    "title": "\n3  Dependence\n",
    "section": "\n3.10 Conditional variance",
    "text": "3.10 Conditional variance\n\nConditional variance\nIf E[Y^2] &lt; \\infty, the conditional variance of Y given the event \\{X=x\\} is \n            Var[Y \\mid X=x] = E[(Y-E[Y \\mid X=x])^2 \\mid X=x].\n        \nThe conditional variance of Y given the random vector X is \n    Var[Y \\mid X] = E[(Y-E[Y \\mid X])^2 \\mid X].",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#best-predictor",
    "href": "sec03_dependence.html#best-predictor",
    "title": "\n3  Dependence\n",
    "section": "\n3.11 Best predictor",
    "text": "3.11 Best predictor\nA typical application is to find a good prediction for the outcome of a random variable Y. Recall that the expected value E[Y] is the best predictor for Y in the sense that g^* = E[Y] minimizes E[(Y-g)^2].\nWith the knowledge of an additional random vector X, we can use the joint distribution of Y and X to improve the prediction of Y.\nIt turns out that the CEF m(X) = E[Y \\mid X] is the best predictor for Y given the information contained in the random vector X:\n\nBest predictor\nIf E[Y^2] &lt; \\infty, then the CEF m(X) = E[Y \\mid X] minimizes the expected squared error E[(Y-g(X))^2] among all predictor functions g(X).\n\n\nLet us find the function g(\\cdot) that minimizes E[(Y-g(X))^2]:\n\\begin{align*}\n        &E[(Y-g(X))^2] = E[(Y-m(X) + m(X) - g(X))^2] \\\\\n        &= \\underbrace{E[(Y-m(X))^2]}_{=(i)} + 2\\underbrace{E[(Y-m(X))(m(X) - g(X))]}_{=(ii)} + \\underbrace{E[(m(X) - g(X))^2]}_{(iii)}\n\\end{align*}\nThe first term (i) does not depend on g(\\cdot) and is finite if E[Y^2] &lt; \\infty.\nFor the second term (ii), we use the LIE and CT: \\begin{align*}\n        &E[(Y-m(X))(m(X) - g(X))] \\\\\n        &= E[E[(Y-m(X))(m(X) - g(X))\\mid X]] \\\\\n        &= E[E[Y-m(X)\\mid X](m(X) - g(X))] \\\\\n        &= E[(\\underbrace{E[Y\\mid X]}_{=m(X)} - m(X))(m(X) - g(X))] = 0\n\\end{align*}\nThe third term (iii) E[(m(X) - g(X))^2] is minimal if m(\\cdot) = g(\\cdot)\nTherefore, m(X) = E[Y\\mid X] minimizes E[(Y-g(X))^2].\nThe best predictor for Y given X is m(X)= E[Y \\mid X], but Y can typically only partially be predicted. We have a prediction error (CEF error) \n        e = Y - E[Y \\mid X].\n     The conditional expectation of the CEF error does not depend on X and is zero: \\begin{align*}\n        E[e \\mid X] &= E[(Y - m(X)) \\mid X] \\\\\n        &= E[Y \\mid X] - E[m(X) \\mid X] \\\\\n        &= m(X) - m(X) = 0\n\\end{align*}\nWe say that Y is conditional mean independent of Z if E[Y \\mid Z] does not depend on Z.\nIf Y and Z are independent, they are also conditional mean independent, but not necessarily vice versa. If Y and Z are conditional mean independent, they are also uncorrelated, but not necessarily vice versa.\nSince the CEF is the best predictor of Y, it is of great interest to study the CEF in practice. Much of the statistical and econometric research deals with methods to approximate and estimate the CEF. This field of statistics is called regression analysis.\nConsider the following model for Y and X: \n    Y = m(X) + e, \\quad E[e \\mid X] = 0.\n   \\tag{3.1} We call m(\\cdot) regression function and e error term.\nFrom equation Equation 3.1 it follows that \n    E[Y \\mid X] = E[m(X) + e \\mid X] = E[m(X) \\mid X] + E[e \\mid X] = m(X).\n     I.e., the nonparametric regression model is a model for the CEF.\nIf m(\\cdot) is a linear function, then Equation 3.1 is a linear regression model. We will study this model in detail in the next sections.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#combining-normal-variables",
    "href": "sec03_dependence.html#combining-normal-variables",
    "title": "\n3  Dependence\n",
    "section": "\n3.12 Combining normal variables",
    "text": "3.12 Combining normal variables\nSome of the distributions commonly encountered in econometrics are combinations of univariate normal distributions, such as the multivariate normal, chi-squared, Student t, and F distributions.\n\n3.12.1 \\chi^2-distribution\nLet Z_1, \\ldots, Z_m be independent \\mathcal N(0,1) random variables. Then, the random variable \n        Y = \\sum_{i=1}^m Z_i^2\n   is chi-square distributed with parameter m, written Y \\sim \\chi^2_m.\nThe parameter m is called the degrees of freedom.\nExpectation and variance: \n        E[Y] = m, \\quad var[Y] = 2m\n    \n\n\n\n\n\n\n\nFigure 3.14: \\chi^2 -distribution\n\n\n\n\n\n3.12.2 F-distribution\nIf Q_1 \\sim \\chi^2_m and Q_2 \\sim \\chi^2_r, and if Q_1 and Q_2 are independent, then \n        Y = \\frac{Q_1/m}{Q_2/r}\n     is F-distributed with parameters m and r, written Y \\sim F_{m,r}.\nThe parameter m is called the degrees of freedom in the numerator; r is the degree of freedom in the denominator.\nIf r \\to \\infty then the distribution of mY approaches \\chi^2_m\n\n\n\n\n\n\n\nFigure 3.15: F-distribution\n\n\n\n\n\n3.12.3 Student t-distribution\nIf Z \\sim \\mathcal N(0,1) and Q \\sim \\chi^2_m, and Z and Q are independent, then \n        Y = \\frac{Z}{\\sqrt{Q/m}}\n     is t-distributed with parameter m degrees of freedom, written Y \\sim t_m.\nExpectation, variance, and moments: \n        E[Y] = 0 \\quad  (\\text{if} \\ m \\geq 2),\n     \n        var[Y] = \\frac{m}{m-2} \\quad (\\text{if} \\ m \\geq 3)\n     The first m-1 moments are finite: E[|Y|^r] &lt; \\infty for r \\leq m-1 and E[|Y|^r] = \\infty for r \\geq m.\nThe t-distribution with m=1 is also called Cauchy distribution. The t-distributions with 1, 2, 3, and 4 degrees of freedom are heavy-tailed distributions. If m \\to \\infty then t_m \\to \\mathcal N(0,1)\n\n\n\n\n\n\n\nFigure 3.16: Student t-distribution\n\n\n\n\n\n3.12.4 Multivariate normal distribution\nLet X_1, \\ldots, X_k be independent \\mathcal N(0,1) random variables. Then, the k-vector X = (X_1, \\ldots, X_k)' has the multivariate standard normal distribution, written X \\sim \\mathcal N(\\boldsymbol 0, \\boldsymbol I_k). Its joint density is \n        f(x) = \\frac{1}{(2 \\pi)^{k/2}} \\exp\\left( - \\frac{x'x}{2} \\right).\n    \nIf X \\sim \\mathcal N(\\boldsymbol 0, \\boldsymbol I_k) and \\widetilde X = \\mu + \\boldsymbol B X for a q \\times 1 vector \\mu and a q \\times k matrix \\boldsymbol B, then \\widetilde X has a multivariate normal distribution with parameters \\mu and \\Sigma = \\boldsymbol B \\boldsymbol B', written \\widetilde X \\sim \\mathcal N(\\mu, \\Sigma). Its joint density is \n        f(x) = \\frac{1}{(2 \\pi)^{k/2} (\\det(\\Sigma))^{1/2} } \\exp\\Big(- \\frac{1}{2}(x-\\mu)'\\Sigma^{-1} (x-\\mu) \\Big).\n\nThe expectation vector and covariance matrix are \n        E[\\widetilde X] = \\mu, \\quad var[\\widetilde X] = \\Sigma.\n    \n\n3.12.5 R-commands for parametric distributions\n\n\n\n\n\n\n\n\n\nget CDFF(a)\n\nquantile functionq(p)\n\ngenerate n independent\nrandom numbers\n\n\n\n\\mathcal N(0,1)\npnorm(a)\nqnorm(p)\nrnorm(n)\n\n\n\\chi^2_r\npchisq(a,r)\nqchisq(p,r)\nrchisq(n,r)\n\n\nt_r\npt(a,r)\nqt(p,r)\nrt(n,r)\n\n\nF_{r,k}\npf(a,r,k)\nqf(p,r,k)\nrf(n,r,k)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "sec03_dependence.html#additional-reading",
    "href": "sec03_dependence.html#additional-reading",
    "title": "\n3  Dependence\n",
    "section": "\n3.13 Additional reading",
    "text": "3.13 Additional reading\n\nStock and Watson (2019), Section 2\nHansen (2022a), Section 4\nHansen (2022b), Section 2\nDavidson and MacKinnon (2004), Section 1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Dependence</span>"
    ]
  },
  {
    "objectID": "stat1_data.html",
    "href": "stat1_data.html",
    "title": "\n4  Data\n",
    "section": "",
    "text": "4.1 Datasets\nA univariate dataset is a sequence of observations Y_1, \\ldots, Y_n. These n observations can be organized into the data vector \\boldsymbol Y, represented as \\boldsymbol Y = (Y_1, \\ldots, Y_n)'. For example, if you conduct a survey and ask five individuals about their hourly earnings, your data vector might look like \n  \\boldsymbol Y = \\begin{pmatrix} 18.22 \\\\ 23.85 \\\\ 10.00 \\\\ 6.39 \\\\ 7.42 \\end{pmatrix}.\n Typically we have data on more than one variable, such as years of education and the gender. Categorical variables are often encoded as dummy variables, which are binary variables. The female dummy variable is defined as 1 if the gender of the person is female and 0 otherwise.\nperson\nwage\neducation\nfemale\n\n\n\n1\n18.22\n16\n1\n\n\n2\n23.85\n18\n0\n\n\n3\n10.00\n16\n1\n\n\n4\n6.39\n13\n0\n\n\n5\n7.42\n14\n0\nA k-variate dataset (or multivariate dataset) is a collection of n vectors \\boldsymbol X_1, \\ldots, \\boldsymbol X_n containing data on k variables. The i-th vector \\boldsymbol X_i = (X_{i1}, \\ldots, X_{ik})' contains the data on all k variables for individual i. Thus, X_{ij} represents the value for the j-th variable of individual i.\nThe full k-variate dataset is structured in the n \\times k data matrix \\boldsymbol X: \n  \\boldsymbol X = \\begin{pmatrix}\n    \\boldsymbol X_1' \\\\ \\vdots \\\\ \\boldsymbol X_n'\n  \\end{pmatrix} = \\begin{pmatrix} X_{11} & \\ldots & X_{1k} \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  X_{n1} & \\ldots & X_{nk} \\end{pmatrix}\n The i-th row in \\boldsymbol X corresponds to the values from \\boldsymbol X_i. Since \\boldsymbol X_i is a column vector, we use the transpose notation \\boldsymbol X_i', which is a row vector.\nThe data matrix for our example is \n\\boldsymbol X = \\begin{pmatrix}\n  18.22 & 16 & 1 \\\\\n  23.85 & 18 & 0 \\\\\n  10.00 & 16 & 1 \\\\\n  6.39 & 13 & 0 \\\\\n  7.42 & 14 & 0\n  \\end{pmatrix}\n with data vectors \n\\boldsymbol X_1 = \\begin{pmatrix} 18.22 \\\\ 16 \\\\ 1 \\end{pmatrix}, \\\n  \\boldsymbol X_2 = \\begin{pmatrix} 23.85 \\\\ 18 \\\\ 0 \\end{pmatrix}, \\ \\ldots \\ .\nVector and matrix algebra provide a compact mathematical representation of multivariate data and an efficient framework for analyzing and implementing statistical methods. We will use matrix algebra frequently throughout this course.\nTo refresh or enhance your knowledge of matrix algebra, please consult the following resources:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "stat1_data.html#datasets",
    "href": "stat1_data.html#datasets",
    "title": "\n4  Data\n",
    "section": "",
    "text": "Crash Course on Matrix Algebra:\n\n\n\nmatrix.svenotto.com\nSection 19.1 of the Stock and Watson textbook also provides a brief overview of matrix algebra concepts.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "stat1_data.html#r-programming-language",
    "href": "stat1_data.html#r-programming-language",
    "title": "\n4  Data\n",
    "section": "\n4.2 R programming language",
    "text": "4.2 R programming language\nThe best way to learn statistical methods is to program and apply them yourself. Throughout this course, we will use the R programming language for implementing empirical methods and analyzing real-world datasets.\nIf you are just starting with R, it is crucial to familiarize yourself with its basics. Here’s an introductory tutorial, which contains a lot of valuable resources:\n\n\n\n\n\n\nGetting Started with R:\n\n\n\nrintro.svenotto.com\n\n\nFor those new to R, I also recommend the interactive R package SWIRL, which offers an excellent way to learn directly within the R environment. Additionally, a highly recommended online book to learn R programming is Hands-On Programming with R.\nOne of the best features of R is its extensive ecosystem of packages contributed by the statistical community. You find R packages for almost any statistical method out there and many statisticians provide R packages to accompany their research.\nOne of the most frequently used packages in applied econometrics is the AER package (“Applied Econometrics with R”), which provides a comprehensive collection of inferential methods for linear models. You can install the package with the command install.packages(\"AER\") and you can load it with\n\nlibrary(AER)\n\nat the beginning of your code. We will explore several additional packages in the course of the lecture.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "stat1_data.html#datasets-in-r",
    "href": "stat1_data.html#datasets-in-r",
    "title": "\n4  Data\n",
    "section": "\n4.3 Datasets in R",
    "text": "4.3 Datasets in R\nR includes many built-in datasets and packages of datasets that can be loaded directly into your R environment. For illustration, we consider the CASchools dataset available in the AER package. This dataset is used in the Stock and Watson textbook Introduction to Econometrics in Sections 4–8. It contains information on various characteristics of schools in California, such as test scores, teacher salaries, and student demographics. The data were collected in 1998.\nThe dataset contains the following variables:\n\n\nVariable\nDescription\n\n\n\ndistrict\nSchool district ID\n\n\nschool\nSchool name\n\n\ncounty\nCounty name\n\n\ngrades\nGrade span: K-6 or K-8\n\n\nstudents\nStudent count\n\n\nteachers\nTeacher count\n\n\ncalworks\n% of CalWorks students\n\n\nlunch\n% receiving free lunch\n\n\ncomputer\nNumber of computers\n\n\nexpenditure\nExpenditure per student\n\n\nincome\nDistrict average income (thousands $)\n\n\nenglish\n% of English learners\n\n\nread\nAverage reading score\n\n\nmath\nAverage math score\n\n\n\n\nTo load this dataset into your R session, simply use:\n\ndata(CASchools, package = \"AER\")\n\nThe Environment pane in RStudio’s top-right corner displays all objects currently in your workspace, including the CASchools dataset. You can click on CASchools to open a table viewer and explore its contents. To get a description of the dataset, use the ?CASchools command. The head() function displays its first few rows:\n\nhead(CASchools)\n\n  district                          school  county grades students teachers\n1    75119              Sunol Glen Unified Alameda  KK-08      195    10.90\n2    61499            Manzanita Elementary   Butte  KK-08      240    11.15\n3    61549     Thermalito Union Elementary   Butte  KK-08     1550    82.90\n4    61457 Golden Feather Union Elementary   Butte  KK-08      243    14.00\n5    61523        Palermo Union Elementary   Butte  KK-08     1335    71.50\n6    62042         Burrel Union Elementary  Fresno  KK-08      137     6.40\n  calworks   lunch computer expenditure    income   english  read  math\n1   0.5102  2.0408       67    6384.911 22.690001  0.000000 691.6 690.0\n2  15.4167 47.9167      101    5099.381  9.824000  4.583333 660.5 661.9\n3  55.0323 76.3226      169    5501.955  8.978000 30.000002 636.3 650.9\n4  36.4754 77.0492       85    7101.831  8.978000  0.000000 651.9 643.5\n5  33.1086 78.4270      171    5235.988  9.080333 13.857677 641.8 639.9\n6  12.3188 86.9565       25    5580.147 10.415000 12.408759 605.7 605.4\n\n\nThe CASchools dataset is stored as a data.frame, R’s most common data storage class for tabular data as in the data matrix \\boldsymbol X. It organizes data in the form of a table, with variables as columns and observations as rows.\n\nclass(CASchools)\n\n[1] \"data.frame\"\n\n\nTo inspect the structure of your dataset, you can use str():\n\nstr(CASchools)\n\n'data.frame':   420 obs. of  14 variables:\n $ district   : chr  \"75119\" \"61499\" \"61549\" \"61457\" ...\n $ school     : chr  \"Sunol Glen Unified\" \"Manzanita Elementary\" \"Thermalito Union Elementary\" \"Golden Feather Union Elementary\" ...\n $ county     : Factor w/ 45 levels \"Alameda\",\"Butte\",..: 1 2 2 2 2 6 29 11 6 25 ...\n $ grades     : Factor w/ 2 levels \"KK-06\",\"KK-08\": 2 2 2 2 2 2 2 2 2 1 ...\n $ students   : num  195 240 1550 243 1335 ...\n $ teachers   : num  10.9 11.1 82.9 14 71.5 ...\n $ calworks   : num  0.51 15.42 55.03 36.48 33.11 ...\n $ lunch      : num  2.04 47.92 76.32 77.05 78.43 ...\n $ computer   : num  67 101 169 85 171 25 28 66 35 0 ...\n $ expenditure: num  6385 5099 5502 7102 5236 ...\n $ income     : num  22.69 9.82 8.98 8.98 9.08 ...\n $ english    : num  0 4.58 30 0 13.86 ...\n $ read       : num  692 660 636 652 642 ...\n $ math       : num  690 662 651 644 640 ...\n\n\nThe dataset contains variables of different types: chr for character/text data, Factor for categorical data, and num for numeric data.\nThe variable students contains the total number of students enrolled in a school. It is the fifth variable in the data set. To access the variable as a vector, you can type CASchools[,5] (the fifth column in your data matrix), or CASchools[,\"students\"], or simply CASchool$students.\nIf you want to select the variables students and teachers, you can type CASchools[,c(\"students\", \"teachers\")]. We can define our own dataframe mydata that contains a selection of variables:\n\nmydata = CASchools[,c(\"students\", \"teachers\", \"english\", \"income\", \"math\", \"read\")]\nhead(mydata)\n\n  students teachers   english    income  math  read\n1      195    10.90  0.000000 22.690001 690.0 691.6\n2      240    11.15  4.583333  9.824000 661.9 660.5\n3     1550    82.90 30.000002  8.978000 650.9 636.3\n4      243    14.00  0.000000  8.978000 643.5 651.9\n5     1335    71.50 13.857677  9.080333 639.9 641.8\n6      137     6.40 12.408759 10.415000 605.4 605.7\n\n\nThe pipe operator |&gt; efficiently chains commands. It passes the output of one function as the input to another. For example, mydata |&gt; head() gives the same output as head(mydata).\nA convenient alternative to select a subset of variables of your dataframe is the select() function from the dplyr package. Let’s chain the select() and head() function:\n\nlibrary(dplyr)\nCASchools |&gt; select(students, teachers, english, income, math, read) |&gt; head()\n\n  students teachers   english    income  math  read\n1      195    10.90  0.000000 22.690001 690.0 691.6\n2      240    11.15  4.583333  9.824000 661.9 660.5\n3     1550    82.90 30.000002  8.978000 650.9 636.3\n4      243    14.00  0.000000  8.978000 643.5 651.9\n5     1335    71.50 13.857677  9.080333 639.9 641.8\n6      137     6.40 12.408759 10.415000 605.4 605.7\n\n\nPiping in R makes code more readable by allowing you to read operations from left to right in a natural order, rather than nesting functions inside each other from the inside out.\nWe can easily add new variables to our dataframe, for instance, the student-teacher ratio (the total number of students per teacher) and the average test score (average of the math and reading scores):\n\n# compute student-teacher ratio and append it to mydata\nmydata$STR = mydata$students/mydata$teachers \n# compute test score and append it to mydata\nmydata$score = (mydata$read+mydata$math)/2   \n\nThe variable english indicates the proportion of students whose first language is not English and who may need additional support. We might be interested in the dummy variable HiEL, which indicates whether the proportion of English learners is above 10 percent or not:\n\n# append HiEL to mydata\nmydata$HiEL = (mydata$english &gt;= 10) |&gt; as.numeric()\n\nNote that mydata$english &gt;= 10 is a logical expression with either TRUE or FALSE values. The command as.numeric() creates a dummy variable by translating TRUE to 1 and FALSE to 0.\nScatterplots provide further insights:\n\nplot(score~STR, data = mydata)\n\n\n\n\n\n\n\n\npar(mfrow = c(1,2))\nplot(score~income, data = mydata)\nplot(score~english, data = mydata)\n\n\n\n\n\n\n\nThe option par(mfrow = c(1,2)) allows to display multiple plots side by side. Try what happens if you replace c(1,2) with c(2,1).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "stat1_data.html#r-codes",
    "href": "stat1_data.html#r-codes",
    "title": "\n4  Data\n",
    "section": "\n4.4 R-codes",
    "text": "4.4 R-codes\nstatistics-sec01.R",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html",
    "href": "stat3_probability.html",
    "title": "\n5  Probability\n",
    "section": "",
    "text": "5.1 Random Sampling\nFrom an empirical perspective, a dataset Y_1, \\ldots, Y_n or \\boldsymbol X_1, \\ldots, \\boldsymbol X_n is just a fixed array of numbers. Any summary statistic we compute – like a sample mean, sample correlation, or OLS coefficient – is simply a function of these numbers.\nThese statistics provide a snapshot of the data at hand but do not automatically reveal broader insights about the world. To add deeper meaning to these numbers, identify dependencies, and understand causalities, we must consider how the data were obtained.\nA random experiment is an experiment whose outcome cannot be predicted with certainty. In statistical theory, any dataset is viewed as the result of such a random experiment.\nThe gender of the next person you meet, daily fluctuations in stock prices, monthly music streams of your favorite artist, or the annual number of pizzas consumed – all involve a certain amount of randomness and emerge from random experiments.\nSampling is the process of drawing observations from a population. Hence, a dataset is also called a sample. Each summary statistic, such as a sample mean or OLS coefficient, is one possible outcome of the random experiment. Repeating the experiment produces a new sample and new statistics.\nIn statistical theory, the population from which we draw observations is treated as infinite. It serves as a theoretical construct that includes not only existing members of a physical population, but all possible future or hypothetical individuals. In coin flip studies, for example, the infinite population represents not just all coin flips ever performed, but all possible coin flips that could theoretically occur in any context at any time.\nThe goal of statistical inference is to learn about the world from the observed sample. This requires assumptions about how the data were collected.\nThe simplest ideal assumption is random sampling, where each observation is drawn independently from the population – like drawing balls from an urn or randomly selecting survey participants. This principle is often called i.i.d. sampling (independent and identically distributed sampling). To define these concepts rigorously, we rely on probability theory.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#random-variables",
    "href": "stat3_probability.html#random-variables",
    "title": "\n5  Probability\n",
    "section": "\n5.2 Random variables",
    "text": "5.2 Random variables\nA random variable is a numerical summary of a random experiment. An outcome is a specific result of a random experiment. The sample space S is the set/collection of all potential outcomes.\nLet’s consider some examples:\n\n\nCoin toss: The outcome of a coin toss can be “heads” or “tails”. This random experiment has a two-element sample space: S = \\{heads, tails\\}. We can express the experiment as a binary random variable: \nY = \\begin{cases}\n1   & \\text{if outcome is heads,} \\\\\n0   & \\text{if outcome is tails.}\n\\end{cases}\n\n\n\nGender: If you conduct a survey and interview a random person to ask them about their gender, the answer may be “female”, “male”, or “diverse”. It is a random experiment since the person to be interviewed is selected randomly. The sample space has three elements: S = \\{female, male, diverse\\}. To focus on female vs. non-female, we can define the female dummy variable: \nY = \\begin{cases}\n1   & \\text{if the person is female,} \\\\\n0   & \\text{if the person is not female.}\n\\end{cases}\n Similarly, dummy variables for male and diverse can be defined.\n\nEducation level: If you ask a random person about their education level according to the ISCED-2011 framework, the outcome may be one of the eight ISCED-2011 levels. We have an eight-element sample space: S = \\{Level \\ 1, Level \\ 2, Level \\ 3, Level \\ 4, Level \\ 5, Level \\ 6, Level \\ 7, Level \\ 8\\}. The eight-element sample space of the education-level random experiment provides a natural ordering. We define the random variable education as the number of years of schooling of the interviewed person: \nY = \\text{years of schooling} \\in \\{4, 10, 12, 13, 14, 16, 18, 21\\}.\n\n\n\n\n\n\nTable 5.1: ISCED 2011 levels\n\n\n\n\nISCED level\nEducation level\nYears of schooling\n\n\n\n1\nPrimary\n4\n\n\n2\nLower Secondary\n10\n\n\n3\nUpper secondary\n12\n\n\n4\nPost-Secondary\n13\n\n\n5\nShort-Cycle Tertiary\n14\n\n\n6\nBachelor's\n16\n\n\n7\nMaster's\n18\n\n\n8\nDoctoral\n21\n\n\n\n\n\n\n\n\n\n\nWage: If you ask a random person about their income per working hour in EUR, there are infinitely many potential answers. Any (non-negative) real number may be an outcome. The sample space is a continuum of different wage levels. The wage level of the interviewed is already numerical. The random variable is \nY = \\text{income per working hour in EUR}.\n\n\n\nRandom variables share the characteristic that their value is uncertain before conducting a random experiment (e.g., flipping a coin or selecting a random person for an interview). Their value is always a real number and is determined only once the experiment’s outcome is known.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#events-and-probabilities",
    "href": "stat3_probability.html#events-and-probabilities",
    "title": "\n5  Probability\n",
    "section": "\n5.3 Events and probabilities",
    "text": "5.3 Events and probabilities\nAn event of a random variable Y is a specific subset of the real line. Any real number defines an event (elementary event), and any open, half-open, or closed interval represents an event as well.\nLet’s define some specific events:\n\nElementary events: \n  A_1 = \\{Y=0\\}, \\quad A_2 = \\{Y=1\\}, \\quad A_3 = \\{Y=2.5\\}\n\n\nHalf-open events: \\begin{align*}\nA_4 &= \\{Y \\geq 0\\} = \\{ Y \\in [0,\\infty) \\} \\\\\nA_5 &= \\{ -1 \\leq Y &lt; 1 \\} = \\{ Y \\in [-1,1) \\}.\n\\end{align*}\n\n\nThe probability function P assigns values between 0 and 1 to events. For a fair coin toss it is natural to assign the following probabilities: \n  P(A_1) = P(Y=0) = 0.5, \\quad P(A_2) = P(Y=1) = 0.5\n By definition, the coin variable will never take the value 2.5, so we assign \n  P(A_3) = P(Y=2.5) = 0.\n To assign probabilities to interval events, we check whether the events \\{Y=0\\} and/or \\{Y=1\\} are subsets of the event of interest.\nIf both \\{Y=0\\} and \\{Y=1\\} are contained in the event of interest, the probability is 1. If only one of them is contained, the probability is 0.5. If neither is contained, the probability is 0. \n  P(A_4) = P(Y \\geq 0) = 1, \\quad P(A_5) = P( -1 \\leq Y &lt; 1) = 0.5.\n\nEvery event has a complementary event, and for any pair of events we can take the union and intersection. Let’s define further events:\n\nComplements: \nA_6 = A_4^c = \\{Y \\geq 0\\}^c = \\{ Y &lt; 0\\} = \\{Y \\in (-\\infty, 0)\\},\n\n\nUnions: \nA_7 = A_1 \\cup A_6 = \\{Y=0\\} \\cup \\{Y&lt; 0\\} = \\{Y \\leq 0\\}\n\n\nIntersections: \nA_8 = A_4 \\cap A_5 = \\{Y \\geq 0\\} \\cap \\{ -1 \\leq Y &lt; 1 \\} = \\{ 0 \\leq Y &lt; 1 \\}\n\n\nIterations of it: \n  A_9 = A_1 \\cup A_2 \\cup A_3 \\cup A_5 \\cup A_6 \\cup A_7 \\cup A_8 = \\{ Y \\in (-\\infty, 1] \\cup \\{2.5\\}\\},\n\n\nCertain event: \nA_{10} = A_9 \\cup A_9^c = \\{Y \\in (-\\infty, \\infty)\\} = \\{Y \\in \\mathbb R\\}\n\n\nEmpty event: \nA_{11} = A_{10}^c = \\{ Y \\notin \\mathbb R \\} = \\{ \\}\n\n\n\nYou may verify that P(A_1) = 0.5, P(A_2) = 0.5, P(A_3) = 0, P(A_4) = 1 P(A_5) = 0.5, P(A_6) = 0, P(A_7) = 0.5, P(A_8) = 0.5, P(A_9) = 1, P(A_{10}) = 1, P(A_{11}) = 0 for the coin toss experiment.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#probability-function",
    "href": "stat3_probability.html#probability-function",
    "title": "\n5  Probability\n",
    "section": "\n5.4 Probability function",
    "text": "5.4 Probability function\nThe probability function P assigns probabilities to events. The set of all events for which probabilities can be assigned is called the Borel sigma-algebra, denoted as \\mathcal B.\nThe previously mentioned events A_1, \\ldots, A_{11} are elements of \\mathcal B. Any event of the form \\{ Y \\in (a,b) \\} with a, b \\in \\mathbb{R} is also in \\mathcal B. Moreover, \\mathcal B includes all possible unions, intersections, and complements of these events. Essentially, it represents the complete collection of events for which we would ever compute probabilities in practice.\nA probability function P must satisfy certain fundamental rules (axioms) to ensure a well-defined probability framework:\n\nBasic rules of probability\n\n\nP(A) \\geq 0 for any event A\n\n\nP(Y \\in \\mathbb R) = 1 for the certain event\n\nP(A \\cup B) = P(A) + P(B)  if A and B are disjoint\n\nP(Y \\notin \\mathbb R) = 0 for the empty event\n\n0 \\leq P(A) \\leq 1  for any event A\n\n\nP(A) \\leq P(B)  if A is a subset of B\n\n\nP(A^c) = 1 - P(A)  for the complement event of A\n\n\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)  for any events A, B\n\n\n\n\nTwo events A and B are disjoint if A \\cap B = \\{\\}, meaning they have no common outcomes. For instance, A_1 = \\{Y=0\\} and A_2 = \\{Y=1\\} are disjoint. However, A_1 and A_4 = \\{Y \\geq 0\\} are not disjoint because their intersection, A_1 \\cap A_4 = \\{Y=0\\}, is nonempty.\nThe first three properties listed above are known as the axioms of probability. The remaining properties follow as logical consequences of these axioms.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#distribution-function",
    "href": "stat3_probability.html#distribution-function",
    "title": "\n5  Probability\n",
    "section": "\n5.5 Distribution function",
    "text": "5.5 Distribution function\nAssigning probabilities to events is straightforward for binary variables, like coin tosses. For instance, knowing that P(Y = 1) = 0.5 allows us to derive the probabilities for all events in \\mathcal B. However, for more complex variables, such as education or wage, defining probabilities for all possible events becomes more challenging due to the vast number of potential set operations involved.\nFortunately, it turns out that knowing the probabilities of events of the form \\{Y \\leq a\\} is enough to determine the probabilities of all other events. These probabilities are summarized in the cumulative distribution function.\n\nCumulative distribution function (CDF)\nThe cumulative distribution function (CDF) of a random variable Y is \n  F(a) := P(Y \\leq a), \\quad a \\in \\mathbb R.\n\n\n\nThe CDF is sometimes simply referred to as the distribution function, or the distribution.\nThe cumulative distribution function (CDF) of the variable coin is \n        F(a) = \\begin{cases} 0 & a &lt; 0, \\\\\n        0.5 & 0 \\leq a &lt; 1, \\\\\n        1 & a \\geq 1, \\end{cases}\n     with the following CDF plot:\n\n\n\n\n\nFigure 5.1: CDF of coin\n\n\nThe CDF of the variable education could be\n\n\n\n\n\nFigure 5.2: CDF of education\n\n\nand the CDF of the variable wage may have the following form:\n\n\n\n\n\nFigure 5.3: CDF of wage\n\n\nThe CDF of a continuous random variable is smooth, while the CDF of a discrete random variable contains jumps and is flat between jumps. For example, variables like coin and education are discrete, whereas wage is continuous.\nAny function F(a) with the following properties defines a valid probability distribution:\n\nNon-decreasing: F(a) \\leq F(b) for a \\leq b;\nLimits at 0 and 1: \\displaystyle \\lim_{a \\to -\\infty} F(a) = 0 and \\displaystyle \\lim_{a \\to \\infty} F(a) = 1\n\nRight-continuity: \\displaystyle \\lim_{\\varepsilon \\to 0, \\varepsilon \\geq 0} F(a + \\varepsilon) = F(a)\n\n\nRight-continuity ensures that cumulative probabilities include the probability at each point, which is especially important for discrete variables with their jump points.\nThe right-continuity property means that the CDF includes the probability mass at each point a, ensuring P(Y \\leq a) includes P(Y = a). This property is particularly important for discrete random variables where there are jumps in the CDF.\nBy the basic rules of probability, we can compute the probability of any event of interest if we know the probabilities of all events of the forms \\{Y \\leq a\\} and \\{Y = a \\}.\n\nSome basic rules for the CDF (for a &lt; b):\n\nP(Y \\leq a) = F(a)\nP(Y &gt; a) = 1 - F(a)\nP(Y &lt; a) = F(a) - P(Y=a)\nP(Y \\geq a) = 1 - P(Y &lt; a)\nP(a &lt; Y \\leq b) = F(b) - F(a)\nP(a &lt; Y &lt; b) = F(b) - F(a) - P(Y=b)\nP(a \\leq Y \\leq b) = F(b) - F(a) + P(Y=a)\nP(a \\leq Y &lt; b) = P(a \\leq Y \\leq b) - P(Y=b)\n\n\n\nA probability of the form P(Y=a), which involves only an elementary event, is called a point probability.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#probability-mass-function",
    "href": "stat3_probability.html#probability-mass-function",
    "title": "\n5  Probability\n",
    "section": "\n5.6 Probability mass function",
    "text": "5.6 Probability mass function\nThe point probability P(Y = a) represents the size of the jump at a \\in \\mathbb{R} in the CDF F(a): \n  P(Y=a) = F(a) - \\lim_{\\epsilon \\to 0, \\varepsilon \\geq 0} F(a-\\varepsilon),\n which is the jump height at a. We summarize the CDF jump heights or point probabilities in the probability mass function:\n\nProbability mass function (PMF)\nThe probability mass function (PMF) of a random variable Y is \n  \\pi(a) := P(Y = a), \\quad a \\in \\mathbb R\n\n\n\nThe PMF of the coin variable is \n  \\pi(a) = P(Y=a) = \\begin{cases} 0.5 & \\text{if} \\ a \\in\\{0,1\\}, \\\\\n  0 & \\text{otherwise}. \\end{cases}\n The education variable may have the following PMF: \n        \\pi(a) = P(Y=a) = \\begin{cases}\n        0.008 & \\text{if} \\ a = 4 \\\\\n        0.048 & \\text{if} \\ a = 10 \\\\\n        0.392 & \\text{if} \\ a = 12 \\\\\n        0.072 & \\text{if} \\ a = 13 \\\\\n        0.155 & \\text{if} \\ a = 14 \\\\\n        0.071 & \\text{if} \\ a = 16 \\\\\n        0.225 & \\text{if} \\ a = 18 \\\\\n        0.029 & \\text{if} \\ a = 21 \\\\\n        0   & \\text{otherwise}\n        \\end{cases}\n  \n\n\n\n\n\n\n\n\n\n(a) CDF of education\n\n\n\n\n\n\n\n\n\n(b) PMF of education\n\n\n\n\n\n\nFigure 5.4\n\n\nBecause continuous variables have no jumps in their CDF, the PMF concept makes only sense for discrete random variables.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#probability-density-function",
    "href": "stat3_probability.html#probability-density-function",
    "title": "\n5  Probability\n",
    "section": "\n5.7 Probability density function",
    "text": "5.7 Probability density function\nFor continuous random variables, the CDF has no jumps, meaning the probability of any specific value is zero, and probability is distributed continuously over intervals. Unlike discrete random variables, which are characterized by both the PMF and the CDF, continuous variables do not have a positive PMF. Instead, they are described by the probability density function (PDF), which serves as the continuous analogue. If the CDF is differentiable, the PDF is given by its derivative:\n\nProbability density function\nThe probability density function (PDF) or simply density function of a continuous random variable Y is the derivative of its CDF: \n    f(a) = \\frac{d}{da} F(a).\n Conversely, the CDF can be obtained from the PDF by integration: \n    F(a) = \\int_{-\\infty}^a f(u) \\ \\text{d}u\n\n\n\nAny function f(a) with the following properties defines a valid probability density function:\n\nNon-negativity: f(a) \\geq 0 for all a \\in \\mathbb R;\nNormalization: \\int_{-\\infty}^\\infty f(u) \\ \\text{d}u = 1.\n\n\n\n\n\n\n\n\n\n\n(a) CDF of wage\n\n\n\n\n\n\n\n\n\n(b) PDF of wage\n\n\n\n\n\n\nFigure 5.5\n\n\n\nBasic rules for continuous random variables (with a \\leq  b):\n\n\\displaystyle P(Y = a) = \\int_a^a f(u) \\ \\text{d}u = 0\n\\displaystyle P(Y \\leq a) = P(Y &lt; a) = F(a) = \\int_{-\\infty}^a f(u) \\ \\text{d}u\n\\displaystyle P(Y &gt; a) = P(Y \\geq a) = 1 - F(a) = \\int_a^\\infty f(u) \\ \\text{d}u\n\\displaystyle P(a &lt; Y &lt; b) = F(b) - F(a) = \\int_a^b f(u) \\ \\text{d}u\n\\displaystyle P(a &lt; Y &lt; b) = P(a &lt; Y \\leq b) = P(a \\leq Y \\leq b) = P(a \\leq Y &lt; b)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#conditional-distribution",
    "href": "stat3_probability.html#conditional-distribution",
    "title": "\n5  Probability\n",
    "section": "\n5.8 Conditional distribution",
    "text": "5.8 Conditional distribution\nThe distribution of wage may differ between men and women. Similarly, the distribution of education may vary between married and unmarried individuals. In contrast, the distribution of a coin flip should remain the same regardless of whether the person tossing the coin earns 15 or 20 EUR per hour.\nThe conditional cumulative distribution function (conditional CDF), F_{Y|Z=b}(a) = F_{Y|Z}(a|b) = P(Y\\leq a|Z=b), represents the distribution of a random variable Y given that another random variable Z takes a specific value b. It answers the question: “If we know that Z=b, what is the distribution of Y?”\nFor example, suppose that Y represents wage and Z represents education\n\n\nF_{Y|Z=12}(a) is the CDF of wages among individuals with 12 years of education.\n\nF_{Y|Z=14}(a) is the CDF of wages among individuals with 14 years of education.\n\nF_{Y|Z=18}(a) is the CDF of wages among individuals with 18 years of education.\n\nSince wage is a continuous variable, its conditional distribution given any specific value of another variable is also continuous. The conditional density of Y given Z=b is defined as the derivative of the conditional CDF: \n        f_{Y|Z=b}(a) = f_{Y|Z}(a|b) = \\frac{d}{d a} F_{Y|Z=b}(a).\n\n\n\n\n\n\n\n\n\n\n(a) Conditional CDFs of wage given education\n\n\n\n\n\n\n\n\n\n(b) Conditional PDFs of wage given education\n\n\n\n\n\n\nFigure 5.6\n\n\nWe observe that the distribution of wage varies across different levels of education. For example, individuals with fewer years of education are more likely to earn less than 20 EUR per hour: \nP(Y\\leq 20 | Z=12) = F_{Y|Z=12}(20) &gt; F_{Y|Z=18}(20) = P(Y\\leq 20|Z = 18).\n Because the conditional distribution of Y given Z=b depends on the value of Z=b we say that the random variables Y and Z are dependent random variables.\nNote that the conditional CDF F_{Y|Z=b}(a) can only be defined for events Z=b that are possible, i.e. b must be in the support of Z.  Formally, the support consists of all b \\in \\mathbb R where the cumulative distribution function F_Z(b) is not flat – meaning it either increases continuously or has a jump. For instance, the support of the variable education is \\{4, 10, 12, 13, 14, 16, 18, 21\\} and the support of the variable wage is \\{a \\in \\mathbb R: a \\geq 0\\}.\nWe can also condition on more than one variable. Let Z_1 represent the labor market experience in years and Z_2 be the female dummy variable. The conditional CDF of Y given Z_1 = b and Z_2 = c is: \nF_{Y|Z_1=b,Z_2=c}(a) = F_{Y|Z_1,Z_2}(a|b,c) = P(Y \\leq a|Z_1=b, Z_2=c).\n\nFor example:\n\n\nF_{Y|Z_1=10,Z_2=1}(a) is the CDF of wages among women with 10 years of experience.\n\nF_{Y|Z_1=10,Z_2=0}(a) is the CDF of wages among men with 10 years of experience.\n\n\n\n\n\n\n\n\n\n\n(a) Conditional CDFs\n\n\n\n\n\n\n\n\n\n(b) Conditional PDFs\n\n\n\n\n\n\nFigure 5.7: Conditional CDFs and PDFs of wage given experience and gender\n\n\n\n\n\n\nClearly the random variable Y and the random vector (Z_1, Z_2) are dependent.\nMore generally, we can condition on the event that a k-variate random vector \\boldsymbol Z = (Z_1, \\ldots, Z_k)' takes the value \\{\\boldsymbol Z = \\boldsymbol b\\}, i.e. \\{Z_1 = b_1, \\ldots, Z_k = b_k\\}. The conditional CDF of Y given \\{\\boldsymbol Z = \\boldsymbol b\\} is \n  F_{Y|\\boldsymbol Z = \\boldsymbol b}(a) = F_{Y|Z_1 = b_1, \\ldots, Z_k = b_k}(a).\n\nThe variable of interest, Y, can also be discrete. Then, any conditional CDF of Y is also discrete. Below is the conditional CDF of education given the married dummy variable:\n\n\nF_{Y|Z=0}(a) is the CDF of education among unmarried individuals.\n\nF_{Y|Z=1}(a) is the CDF of education among married individuals.\n\n\n\n\n\n\nFigure 5.8: Conditional CDFs of education given married\n\n\nThe conditional PMFs \\pi_{Y|Z=0}(a) = P(Y = a | Z=0) and \\pi_{Y|Z=1}(a)= P(Y = a | Z=1) indicate the jump heights of F_{Y|Z=0}(a) and F_{Y|Z=1}(a) at a.\n\n\n\n\n\nFigure 5.9: Conditional PMFs of education given married\n\n\nClearly, education and married are dependent random variables. E.g., \\pi_{Y|Z=0}(12) &gt; \\pi_{Y|Z=1}(12) and \\pi_{Y|Z=0}(18) &lt; \\pi_{Y|Z=1}(18).\nIn contrast, consider Y= coin flip and Z= married dummy variable. The CDF of a coin flip should be the same for married or unmarried individuals:\n\n\n\n\n\n\n\n\n\n(a) Coin flip given married\n\n\n\n\n\n\n\n\n\n(b) Coin flip given unmarried\n\n\n\n\n\n\nFigure 5.10: Conditional CDFs of a coin flip of a married (left) and unmarried (right) individual\n\n\nBecause \n  F_Y(a) = F_{Y|Z=0}(a) = F_{Y|Z=1}(a) \\quad \\text{for all} \\ a\n we say that Y and Z are independent random variables.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#independence-of-random-variables",
    "href": "stat3_probability.html#independence-of-random-variables",
    "title": "\n5  Probability\n",
    "section": "\n5.9 Independence of random variables",
    "text": "5.9 Independence of random variables\n\nIndependence\nY and Z are independent if and only if \n  F_{Y|Z=b}(a) = F_{Y}(a) \\quad \\text{for all} \\ a \\quad \\text{and for almost every} \\ b.\n\n\n\nNote that if F_{Y|Z=b}(a) = F_{Y}(a) for all b, then automatically F_{Z|Y=a}(b) = F_{Y}(b) for all a. Due to this symmetry we can equivalently define independence through the property F_{Z|Y=a}(b) = F_{Z}(b).\nHere, “for almost every b” means for every b in the support of Z, apart from a set of values that has probability 0 under Z. Put differently, the condition must hold for all b-values that Z can actually take, with exceptions allowed only on a set whose probability is 0. Think of it as “for all practical purposes”. The condition must hold for all values b that could realistically occur. For instance, we only need independence to hold for non-negative wages. We don’t need to check independence for negative wages since they can’t occur.\nThe definition naturally generalizes to Z_1, Z_2, Z_3. They are mutually independent if, for each i \\in \\{1,2,3\\}, the conditional distribution of Z_i given the other two equals its marginal distribution. In CDF form, this means:\n\nF_{Z_1|Z_2=b_2, Z_3=b_3}(a) = F_{Z_1}(a)\nF_{Z_2|Z_1=b_1, Z_3=b_3}(a) = F_{Z_2}(a)\nF_{Z_3|Z_1=b_1, Z_2=b_2}(a) = F_{Z_3}(a)\n\nfor all a and for almost every (b_1, b_2, b_3). Here, we need all three conditions.\n\nMutual independence\nThe random variables Z_1, \\ldots, Z_n are mutually independent if and only if, for each i = 1,\\dots,n, \n  F_{Z_i | Z_1=b_1,\\ldots,Z_{i-1}=b_{i-1},\\,Z_{i+1}=b_{i+1},\\ldots,Z_n=b_n}(a)\n=\nF_{Z_i}(a).\n for all a and almost every (b_1, \\ldots, b_n).\n\n\nAn equivalent viewpoint uses the joint CDF of the vector \\boldsymbol Z = (Z_1, \\ldots, Z_n)', which is defined as: \n  F_{\\boldsymbol Z}(\\boldsymbol a) = F_{Z_1, \\ldots, Z_n}(a_1, \\ldots, a_n) = P(Z_1 \\leq a_1, \\ldots, Z_n \\leq a_n) = P(\\boldsymbol Z \\leq \\boldsymbol a),\n where \nP(Z_1 \\leq a_1, \\ldots, Z_n \\leq a_n) = P(\\{Z_1 \\leq a_1\\} \\cap \\ldots \\cap \\{Z_n \\leq a_n\\}).\n Then Z_1, \\ldots, Z_n are mutually independent if and only if the joint CDF is the product of the marginal CDFs: \n  F_{\\boldsymbol Z}(\\boldsymbol a) = F_{Z_1}(a_1) \\cdots F_{Z_n}(a_n) \\quad \\text{for all} \\ a_1, \\ldots, a_n.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#independence-of-random-vectors",
    "href": "stat3_probability.html#independence-of-random-vectors",
    "title": "\n5  Probability\n",
    "section": "\n5.10 Independence of random vectors",
    "text": "5.10 Independence of random vectors\nOften in practice, we work with multiple variables recorded for different individuals or time points. For example, consider two random vectors: \n  \\boldsymbol{X}_1 = (X_{11}, \\ldots, X_{1k})',\n  \\quad\n  \\boldsymbol{X}_2 = (X_{21}, \\ldots, X_{2k})'.\n The conditional distribution function of \\boldsymbol{X}_1 given that \\boldsymbol{X}_2 takes the value \\boldsymbol{b}=(b_1,\\ldots,b_k)' is \n  F_{\\boldsymbol{X}_1 | \\boldsymbol{X}_2 = \\boldsymbol{b}}(\\boldsymbol{a})\n  =\n  P(\\boldsymbol{X}_1 \\le \\boldsymbol{a}|\\boldsymbol{X}_2 = \\boldsymbol{b}),\n where \\boldsymbol{X}_1 \\le \\boldsymbol{a} means X_{1j} \\le a_j for each coordinate j=1,\\ldots,k.\nFor instance, if \\boldsymbol{X}_1 and \\boldsymbol{X}_2 represent the survey answers of two different, randomly chosen people, then F_{\\boldsymbol{X}_2 | \\boldsymbol{X}_1=\\boldsymbol{b}}(\\boldsymbol{a}) describes the distribution of the second person’s answers, given that the first person’s answers are \\boldsymbol{b}. If the two people are truly randomly selected and unrelated to one another, we would not expect \\boldsymbol{X}_2 to depend on whether \\boldsymbol{X}_1 equals \\boldsymbol{b} or some other value \\boldsymbol{c}. In other words, knowing \\boldsymbol X_1 provides no information that changes the distribution of \\boldsymbol X_2.\n\nIndependence of random vectors\nTwo random vectors \\boldsymbol{X}_1 and \\boldsymbol{X}_2 are independent if and only if \nF_{\\boldsymbol{X}_1 | \\boldsymbol{X}_2 = \\boldsymbol{b}}(\\boldsymbol{a})\n=\nF_{\\boldsymbol{X}_1}(\\boldsymbol{a})\n\\quad\n\\text{for all } \\boldsymbol{a}\n\\quad\n\\text{and for almost every } \\boldsymbol{b}.\n\n\n\nThis definition extends naturally to mutual independence of n random vectors \\boldsymbol{X}_1,\\dots,\\boldsymbol{X}_n, where \\boldsymbol{X}_i = (X_{i1},\\dots,X_{ik})'. They are called mutually independent if, for each i = 1,\\dots,n, \n  F_{\\boldsymbol X_i| \\boldsymbol X_1=\\boldsymbol b_1, \\ldots, \\boldsymbol X_{i-1}=\\boldsymbol b_{i-1}, \\boldsymbol X_{i+1}=\\boldsymbol b_{i+1}, \\ldots, \\boldsymbol X_n = \\boldsymbol b_n}(\\boldsymbol a) = F_{\\boldsymbol X_i}(\\boldsymbol a)\n for all \\boldsymbol{a} and almost every (\\boldsymbol{b}_1,\\dots,\\boldsymbol{b}_n).\nHence, in an independent sample, what the i-th randomly chosen person answers does not depend on anyone else’s answers.\n\ni.i.d. sample / random sample\nA collection of random vectors \\boldsymbol{X}_1, \\dots, \\boldsymbol{X}_n is i.i.d. (independent and identically distributed) if they are mutually independent and have the same distribution function F. Formally, \n  F_{\\boldsymbol X_i| \\boldsymbol X_1=\\boldsymbol b_1, \\ldots, \\boldsymbol X_{i-1}=\\boldsymbol b_{i-1}, \\boldsymbol X_{i+1}=\\boldsymbol b_{i+1}, \\ldots, \\boldsymbol X_n = \\boldsymbol b_n}(\\boldsymbol a) = F(\\boldsymbol a)\n for all i=1, \\ldots, n, for all \\boldsymbol{a}, and almost all (\\boldsymbol{b}_1,\\dots,\\boldsymbol{b}_n).\nAn i.i.d. dataset (or random sample) is one where each observation not only comes from the same population distribution F but is independent of the others. The function F is called the population distribution or the data-generating process (DGP).\n\n\nThe CPS data are cross-sectional data: n individuals are randomly selected from the U.S. population and independently interviewed on k variables. Consequently, these n observations form an i.i.d. sample.\nIf Y_1, \\ldots, Y_n are i.i.d., then \\log(Y_1), \\ldots, \\log(Y_n) are also i.i.d. In fact, any identical transformation of each observation preserves the independence and identical distribution. More formally, if \\boldsymbol X_1, \\ldots, \\boldsymbol X_n is i.i.d., then g(\\boldsymbol X_1), \\ldots, g(\\boldsymbol X_n) is i.i.d. as well, for any function g(\\cdot). For instance, if the wages of n interviewed individuals are i.i.d., then their log-wages are also i.i.d.\nSampling methods of obtaining economic datasets that may be considered as random sampling are:\n\n\nSurvey sampling\nExamples: representative survey of randomly selected households from a list of residential addresses; online questionnaire to a random sample of recent customers\n\nAdministrative records\nExamples: data from a government agency database, Statistisches Bundesamt, ECB, etc.\n\nDirect observation\nCollected data without experimental control and interactions with the subject. Example: monitoring customer behavior in a retail store\n\nWeb scraping\nExamples: collected house prices on real estate sites or hotel/electronics prices on booking.com/amazon, etc.\n\nField experiment\nTo study the impact of a treatment or intervention on a treatment group compared with a control group. Example: testing the effectiveness of a new teaching method by implementing it in a selected group of schools and comparing results to other schools with traditional methods\n\nLaboratory experiment\nExample: a controlled medical trial for a new drug\n\nExamples of cross-sectional data sampling that may produce some dependence across observations are:\n\nStratified sampling\nThe population is first divided into homogenous subpopulations (strata), and a random sample is obtained from each stratum independently. Examples: divide companies into industry strata (manufacturing, technology, agriculture, etc.) and sample from each stratum; divide the population into income strata (low-income, middle-income, high-income).\nThe sample is independent within each stratum, but it is not between different strata. The strata are defined based on specific characteristics that may be correlated with the variables collected in the sample.\nClustered sampling\nEntire subpopulations are drawn. Example: new teaching methods are compared to traditional ones on the student level, where only certain classrooms are randomly selected, and all students in the selected classes are evaluated.\nWithin each cluster (classroom), the sample is dependent because of the shared environment and teacher’s performance, but between classrooms, it is independent.\n\nOther types of data we often encounter in econometrics are time series data, panel data, or spatial data:\n\nTime series data consists of observations collected at different points in time, such as stock prices, daily temperature measurements, or GDP figures. These observations are ordered and typically show temporal trends, seasonality, and autocorrelation.\nPanel data involves observations collected on multiple entities (e.g., individuals, firms, countries) over multiple time periods. Every entity thus forms a cluster, within which there is a time series of observations. In this sense, panel data is a specific form of clustered sampling.\nSpatial data includes observations taken at different geographic locations, where values at nearby locations are often correlated.\n\nTime series, panel, and spatial data cannot be considered a random sample given their temporal or geographic dependence.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat3_probability.html#r-codes",
    "href": "stat3_probability.html#r-codes",
    "title": "\n5  Probability\n",
    "section": "\n5.11 R-codes",
    "text": "5.11 R-codes\nstatistics-sec04.R",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html",
    "href": "stat4_expectation.html",
    "title": "6  Expectated value",
    "section": "",
    "text": "6.1 Discrete random variables\nRecall that a discrete random variable Y is a variable that can take on a countable number of distinct values. Each possible value a has an associated probability \\pi(a)=P(Y=a), known as the probability mass function (PMF).\nThe support \\mathcal Y of Y is the set of all values that Y can take with non-zero probability: \\mathcal{Y} = \\{ a \\in \\mathbb{R} : \\pi(a) &gt; 0 \\}. The total probability sums to 1: \\sum_{a \\in \\mathcal Y} \\pi(a)= 1.\nThe expected value of the variable education from the previous section is calculated by summing over all possible values: \\begin{align*}\n  E[Y] &= 4\\cdot\\pi(4) + 10\\cdot\\pi(10) + 12\\cdot \\pi(12) \\\\\n  &\\phantom{=} + 13\\cdot\\pi(13) + 14\\cdot\\pi(14) + 16\\cdot \\pi(16) \\\\\n  &\\phantom{=} + 18 \\cdot \\pi(18) + 21 \\cdot \\pi(21) = 14.117\n\\end{align*}\nA binary or Bernoulli random variable Y takes on only two possible values: 0 and 1. The support is \\mathcal Y = \\{0,1\\}. The probabilities are\nfor some p \\in (0,1). The expected value of Y is: \\begin{align*}\n  E[Y] &=0\\cdot\\pi(0) + 1\\cdot\\pi(1) \\\\\n  &= 0 \\cdot(1-p) + 1 \\cdot p \\\\\n  &= p.\n\\end{align*} For the variable coin, the probability of heads is p=0.5 and the expected value is E[Y] = p = 0.5.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#discrete-random-variables",
    "href": "stat4_expectation.html#discrete-random-variables",
    "title": "6  Expectated value",
    "section": "",
    "text": "The expectation or expected value of a discrete random variable Y with PMF \\pi(\\cdot) and support \\mathcal Y is defined as \n    E[Y] =\n    \\sum_{u \\in \\mathcal Y} u \\pi(u).\n\\tag{6.1}\n\n\n\n\n\\pi(1) = P(Y=1) = p\n\\pi(0) = P(Y=0) = 1-p",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#continuous-random-variables",
    "href": "stat4_expectation.html#continuous-random-variables",
    "title": "6  Expectated value",
    "section": "6.2 Continuous random variables",
    "text": "6.2 Continuous random variables\nFor discrete random variables, both the PMF and the CDF characterize the distribution. For continuous random variables, the PMF concept does not apply because the probability of any specific point is zero. The continuous counterpart of the PMF is the density function:\n\nProbability density function\nThe probability density function (PDF) or simply density function of a continuous random variable Y with CDF F(a) is a function f(a) that satisfies \n    F(a) = \\int_{-\\infty}^a f(u) \\ \\text{d}u\n If the CDF is differentiable, the density f(a) is its derivative: \n    f(a) = \\frac{d}{da} F(a).\n\n\n\n\nProperties of a PDF:\n\nf(a) \\geq 0 for all a \\in \\mathbb R\n\\int_{-\\infty}^\\infty f(u) \\ \\text{d}u = 1\n\n\n\n\n\n\n\nFigure 6.1: CDF of wage\n\n\n\n\n\n\n\n\n\nFigure 6.2: PDF of wage\n\n\n\nProbability rule for the PDF: \n  P(a &lt; Y &lt; b) = \\int_a^b f(u) \\ \\text{d} u = F(b) - F(a)\n\n\nThe expectation or expected value of a continuous random variable Y with PDF f(\\cdot) is \n    E[Y] =\n    \\int_{-\\infty}^\\infty u f(u) \\ \\text{d}u.\n\\tag{6.2}\n\nThe uniform distribution on the unit interval [0,1] has the PDF \n  f(u) = \\begin{cases} 1 & \\text{if} \\ u \\in[0,1], \\\\ 0 & \\text{otherwise,} \\end{cases}\n\\tag{6.3} and the expected value of a uniformly distributed random variable Y is \n  E[Y] = \\int_{-\\infty}^\\infty u f(u) \\ \\text{d} u = \\int_{0}^1 u \\ \\text{d} u = \\frac{1}{2} u^2 \\ \\bigg|_0^1= \\frac{1}{2}.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#sec-unifiedE",
    "href": "stat4_expectation.html#sec-unifiedE",
    "title": "6  Expectated value",
    "section": "6.3 Unified definition of the expected value",
    "text": "6.3 Unified definition of the expected value\nThe expected value of a random variable Y can be defined in a unified way that applies to both discrete and continuous cases by using its CDF F(u): \n  E[Y] =\n    \\int_{-\\infty}^\\infty u \\ \\text{d}F(u).\n\\tag{6.4}\nThis integral, known as the Riemann-Stieltjes integral, generalizes the concept of integration to include functions that may not be smooth or differentiable everywhere.\nFor a continuous random variable with PDF f(u), the CDF F(u) is smooth and differentiable. The relationship between the CDF and the PDF is: \\text{d}F(u)=f(u) \\ \\text{d}u. Substituting this into our unified definition gives: \\begin{align*}\n  E[Y] &=\n    \\int_{-\\infty}^\\infty u \\ \\text{d}F(u) \\\\\n    &= \\int_{-\\infty}^\\infty u f(u) \\ \\text{d}u,\n\\end{align*} which matches the standard definition of the expected value for continuous random variables as in Equation 6.2.\nFor a discrete random variable, the CDF F(u) is a step function that increases in jumps at the possible values u \\in \\mathcal Y that Y can take. The “change” or jump in the CDF at each u \\in \\mathcal Y is: \n  \\Delta F(u) = F(u) - F(u^-) = P(Y=u) = \\pi(u),\n where F(u^-) is the value of F(u) just before u, and \\pi(u) is the PMF of Y.\nIntegrating with respect to F(u) simplifies to summing over these jumps: \\begin{align*}\n  E[Y] &=\n    \\int_{-\\infty}^\\infty u \\ \\text{d}F(u) \\\\\n    &= \\sum_{u \\in \\mathcal Y} u \\ \\Delta F(u) \\\\\n    &= \\sum_{u \\in \\mathcal Y} u \\pi(u),\n\\end{align*} which aligns with the standard definition of the expected value for discrete random variables as in Equation 6.1.\nThe unified definition E[Y]= \\int_{-\\infty}^\\infty u \\ \\text{d}F(u) allows us to treat all types of random variables consistently, whether the variable is discrete, continuous, or a mixture of both. It can also handle non-standard cases such as distributions with CDFs that are not differentiable everywhere.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#transformed-variables",
    "href": "stat4_expectation.html#transformed-variables",
    "title": "6  Expectated value",
    "section": "6.4 Transformed variables",
    "text": "6.4 Transformed variables\nWe often transform random variables by taking, for instance, squares Y^2 or logs \\log(Y). For any transformation function g(\\cdot), the expectation of the transformed random variable g(Y) is \n  E[g(Y)] = \\int_{-\\infty}^\\infty g(u) \\ \\text{d}F(u),\n where F(u) is the CDF of Y. As discussed in Section 6.3 for the different cases, \\text{d}F(u) can be replaced by the PMF or the PDF, i.e., \n  \\int_{-\\infty}^\\infty g(u) \\ \\text{d}F(u) = \\begin{cases}\n      \\sum_{u \\in \\mathcal Y} g(u) \\pi(u) & \\text{if} \\ Y \\ \\text{is discrete,} \\\\\n      \\int_{-\\infty}^\\infty g(u) f(u)\\text{d}u & \\text{if} \\ Y \\ \\text{is continuous.} \\end{cases}\n\nFor instance, if we take the coin variable Y and consider the transformed random variable \\log(Y+1), the expected value is \n  E[\\log(Y+1)] = \\log(1) \\cdot \\frac{1}{2} + \\log(2) \\cdot \\frac{1}{2} = \\frac{\\log(2)}{2}\n We can define the population counterparts of the sample moments and their centralized and standardized versions:\n\nr-th moment of Y: \n  E[Y^r] = \\int_{-\\infty}^\\infty u^r \\ \\text{d}F(u)\n\nr-th central moment: \n  E[(Y-E[Y])^r] = \\int_{-\\infty}^\\infty (u - E[Y])^r \\ \\text{d}F(u)\n\nVariance (2nd central moment): \nVar[Y] = E[(Y-E[Y])^2] = \\int_{-\\infty}^\\infty (u - E[Y])^2 \\ \\text{d}F(u)\n\nStandard deviation: \nsd(Y) = \\sqrt{Var[Y]}\n\nr-th standardized moment: \nE \\bigg[ \\Big(\\frac{Y-E[Y]}{sd(Y)}\\Big)^r \\bigg] = \\int_{-\\infty}^\\infty \\Big(\\frac{u-E[Y]}{sd(Y)}\\Big)^r \\ \\text{d}F(u)\n\nSkewness (3rd standardized moment): \nskew(Y) =  E \\bigg[ \\Big(\\frac{Y-E[Y]}{sd(Y)}\\Big)^3 \\bigg]\n\nKurtosis (4th standardized moment): \nkurt(Y) = E \\bigg[ \\Big(\\frac{Y-E[Y]}{sd(Y)}\\Big)^4 \\bigg]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#linearity-of-the-expected-value",
    "href": "stat4_expectation.html#linearity-of-the-expected-value",
    "title": "6  Expectated value",
    "section": "6.5 Linearity of the expected value",
    "text": "6.5 Linearity of the expected value\nThe expected value is a linear function. For any a,b \\in \\mathbb R, we have \n  E[aY + b] = a E[Y] + b.\n For the variance, the following rule applies: \n  Var[aY + b] = a^2 Var[Y].\n\nFor any two random variables Y and Z, we have \n  E[aY + bZ] = aE[Y] + bE[Z].\n A similar result for the variance does not hold in general. However, if Y and Z are independent random variables, we have \n  Var[aY + bZ] = a^2 Var[Y] + b^2 Var[Z].\n\\tag{6.5}",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#parameters-and-estimators",
    "href": "stat4_expectation.html#parameters-and-estimators",
    "title": "6  Expectated value",
    "section": "6.6 Parameters and estimators",
    "text": "6.6 Parameters and estimators\nA parameter \\theta is a feature (function) of the population distribution F of some random variable Y. The expectation, variance, skewness, and kurtosis are parameters.\nA statistic is a function of a sample Y_1, \\ldots, Y_n. An estimator \\widehat \\theta for \\theta is a statistic intended as a guess about \\theta. It is a function of the random variables Y_1, \\ldots, Y_n and, therefore, a random variable as well. The sample mean, sample variance, sample skewness and sample kurtosis are estimators. When an estimator \\widehat \\theta is calculated in a specific realized sample, we call \\widehat \\theta an estimate.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#estimation-of-the-mean",
    "href": "stat4_expectation.html#estimation-of-the-mean",
    "title": "6  Expectated value",
    "section": "6.7 Estimation of the mean",
    "text": "6.7 Estimation of the mean\nThe expected value E[Y] is also called population mean because it is the population counterpart of the sample mean \\overline Y = \\frac{1}{n} \\sum_{i=1}^n Y_i, where the sample Y_1, \\ldots, Y_n is identically distributed and has the same distribution as Y. In particular, we have: \n  E[Y_1] = \\ldots = E[Y_n] = E[Y].\n\nThe true population mean E[Y] is unknown in practice, but we can use the sample mean \\overline Y to estimate it. The sample mean is an unbiased estimator for the population mean because \n  E[\\overline Y] = \\frac{1}{n} \\sum_{i=1}^n E[Y_i] = \\frac{1}{n} \\sum_{i=1}^n E[Y] = E[Y].\n The bias of an estimator is the expected value of the estimator minus the parameter to be estimated. The bias of the sample mean is zero: \n  Bias[\\overline Y] = E[\\overline Y] - E[Y] = E[Y] - E[Y] = 0.\n When repeating random experiments and computing sample means, we can expect the sample means to be distributed around the true population mean, with the population mean at the center of this distribution.\nTo assess how large the spread around the true population mean is, we can compute the variance: \n  Var[\\overline Y] = \\frac{1}{n^2} Var\\bigg[ \\sum_{i=1}^n Y_i \\bigg]\n To simplify this term further, let’s assume that the sample is i.i.d. (independent and identically distributed), i.e. the observations are randomly sampled from the population. Then, we can apply Equation 6.5: \n  Var\\bigg[ \\sum_{i=1}^n Y_i \\bigg] = \\sum_{i=1}^n Var[Y_i].\n By the identical distribution of the sample, we have \n  Var[Y_1] = \\ldots = Var[Y_n] = Var[Y].\n Therefore, the variance of the sample mean becomes: \n  Var[\\overline Y] = \\frac{1}{n^2} \\sum_{i=1}^n Var[Y_i] =  \\frac{1}{n^2} \\sum_{i=1}^n Var[Y] = \\frac{Var[Y]}{n}.\n The spread of sample means around the true mean becomes smaller, the larger the sample size n is. The more observations we have, the more precisely the sample mean can estimate the true population mean.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#consistency",
    "href": "stat4_expectation.html#consistency",
    "title": "6  Expectated value",
    "section": "6.8 Consistency",
    "text": "6.8 Consistency\nGood estimators get closer and closer to the true parameter being estimated as the sample size n increases, eventually returning the true parameter value in a hypothetically infinitely large sample. This property is called consistency.\n\nConsistency\nAn estimator \\widehat \\theta is consistent for a true parameter \\theta if, for any \\epsilon &gt; 0, \nP(|\\widehat \\theta - \\theta| &gt; \\epsilon) \\to 0 \\qquad \\text{as} \\ n \\to \\infty.\n Equivalently, consistency can be defined by the complementary event: \n  P(|\\widehat \\theta - \\theta| \\leq \\epsilon) \\to 1 \\qquad \\text{as} \\ n \\to \\infty.\n If \\widehat \\theta is consistent, we say it converges in probability to \\theta, denoted by \n  \\widehat \\theta \\overset{p} \\to \\theta \\qquad \\text{as} \\ n \\to \\infty.\n\n\nIf an estimator \\widehat \\theta is a continuous random variable, it will almost never reach exactly the true parameter value because point probabilities are zero: P(\\widehat \\theta = \\theta) = 0.\nHowever, the larger the sample size, the higher should be the probability that \\widehat \\theta is close to the true value \\theta. Consistency means that, if we fix some small precision value \\epsilon &gt; 0, then, P(|\\widehat \\theta - \\theta| \\leq \\epsilon) = P( \\theta - \\epsilon \\leq \\widehat \\theta \\leq \\theta + \\epsilon) should increase in the sample size n and eventually reach 1.\nAn estimator is called inconsistent if it is not consistent. An inconsistent estimator is practically useless and leads to false inference. Therefore, it is important to verify that your estimator is consistent.\nTo show whether an estimator is consistent, we can check the sufficient condition for consistency:\n\nSufficient condition for consistency\nLet \\widehat \\theta be an estimator for some parameter \\theta. The bias of \\widehat \\theta is Bias[\\widehat \\theta] = E[\\widehat \\theta] - \\theta.\nIf the bias and the variance of \\widehat \\theta tends to zero for large sample sizes, i.e., if\n\nBias[\\widehat \\theta] \\rightarrow 0  (as n \\to \\infty),\nVar[\\widehat \\theta] \\rightarrow 0  (as n \\to \\infty),\n\nthen \\widehat \\theta is consistent for \\theta.\n\nThe reason for this sufficient condition is the fact that \n  P(|\\widehat \\theta - \\theta| &gt; \\epsilon) \\leq Var[\\widehat \\theta] + Bias[\\widehat \\theta]^2,\n which follows from Markov’s inequality.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#law-of-large-numbers",
    "href": "stat4_expectation.html#law-of-large-numbers",
    "title": "6  Expectated value",
    "section": "6.9 Law of large numbers",
    "text": "6.9 Law of large numbers\nThe sample mean \\overline Y of an i.i.d. sample is consistent for the population mean E[Y] because\n\nBias[\\overline Y] = 0 for all n;\nVar[\\overline Y] = Var[Y]/n \\to 0, as n \\to \\infty, provided Var[Y] &lt; \\infty.\n\nThe consistency result of the sample mean is also known as the law of large numbers (LLN): \n  \\overline Y \\overset{p} \\to E[Y] \\qquad \\text{as} \\ n \\to \\infty.\n Below is an interactive Shiny app to visualize the law of large numbers using simulated data for different sample sizes and different distributions.\n\nSHINY APP: LLN",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#heavy-tails",
    "href": "stat4_expectation.html#heavy-tails",
    "title": "6  Expectated value",
    "section": "6.10 Heavy tails",
    "text": "6.10 Heavy tails\nThe sample mean of i.i.d. samples from most distributions is consistent. However, there are some exceptional cases where consistency fails. For instance, the simple Pareto distribution has the PDF \n  f(u) = \\begin{cases} \\frac{1}{u^2} & \\text{if} \\ u &gt; 1, \\\\\n  0 & \\text{if} \\ u \\leq 1, \\end{cases}\n and the expected value is \n  E[X] = \\int_{-\\infty}^\\infty u f(u) \\ \\text{d}u\n  = \\int_{1}^\\infty  \\frac{1}{u} \\ \\text{d}u = \\log(u)|_1^\\infty = \\infty.\n The population mean is infinity, so the sample mean cannot converge and is inconsistent. The game of chance from the St. Petersburg paradox (see https://en.wikipedia.org/wiki/St._Petersburg_paradox) is an example of a discrete random variable with infinite expectation.\nAnother example is the t-distribution with 1 degree of freedom, also denoted as t_1 or Cauchy distribution, which has the PDF \n  f(u) = \\frac{1}{\\pi (1+u^2)}.\n The lack of consistency of the sample mean from a t_1 distribution is visualized in the shiny application above.\nThe Pareto, St. Petersburg, and Cauchy distributions have infinite population mean, and the sample mean of observations from these distributions is inconsistent. These are distributions that produce huge outliers.\nThere are other distributions that have a finite mean but an infinite variance, skewness, or kurtosis.\nFor instance, the t_2 distribution has a finite mean but an infinite variance. The t_3 distribution has a finite variance but an infinite skewness. The t_4 distribution has a finite skewness but an infinite kurtosis.\nIf Y is t_m-distributed (t-distribution with m degrees of freedom), then \n  E[Y], E[Y^2], \\ldots, E[Y^{m-1}] &lt; \\infty\n but \n  E[Y^m] = E[Y^{m+1}] = \\ldots = \\infty.\n\nRandom variables with infinite first four moments have a so-called heavy-tailed distribution and may produce huge outliers. Many statistical procedures are only valid if the underlying distribution is not heavy-tailed.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#sec-varianceest",
    "href": "stat4_expectation.html#sec-varianceest",
    "title": "6  Expectated value",
    "section": "6.11 Estimation of the variance",
    "text": "6.11 Estimation of the variance\nConsider an i.i.d. sample Y_1, \\ldots, Y_n from some population distribution with population mean \\mu = E[Y] and population variance \\sigma^2 = Var[Y] &lt; \\infty.\nWe introduced two sample cointerparts of \\sigma^2: the sample variance \n  \\widehat \\sigma_Y^2 = \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\overline Y)^2,\n and the adjusted sample variance \n  s_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\overline Y)^2 = \\frac{n}{n-1} \\widehat \\sigma_Y^2.\n\nThe sample variance can be decomposed as \\begin{align*}\n        \\widehat \\sigma_Y^2 &= \\frac{1}{n} \\sum_{i=1}^n (Y_i - \\overline Y)^2\n        =\\frac{1}{n} \\sum_{i=1}^n (Y_i - \\mu + \\mu - \\overline Y)^2 \\\\\n        &= \\frac{1}{n} \\sum_{i=1}^n(Y_i - \\mu)^2 + \\frac{2}{n} \\sum_{i=1}^n (Y_i - \\mu)(\\mu - \\overline Y) + \\frac{1}{n} \\sum_{i=1}^n (\\mu - \\overline Y)^2 \\\\\n        &= \\frac{1}{n} \\sum_{i=1}^n(Y_i - \\mu)^2 - 2(\\overline Y - \\mu)^2 + (\\overline Y - \\mu)^2 \\\\\n            &= \\frac{1}{n} \\sum_{i=1}^n(Y_i - \\mu)^2  - (\\overline Y - \\mu)^2\n    \\end{align*} The mean of \\widehat \\sigma_Y^2 is \\begin{align*}\n        E[\\widehat \\sigma_Y^2] &= \\frac{1}{n} \\sum_{i=1}^n E[(Y_i - \\mu)^2] - E[(\\overline Y - \\mu)^2] = \\frac{1}{n} \\sum_{i=1}^n Var[Y_i] - Var[\\overline Y] \\\\\n        &= \\sigma^2 - \\frac{\\sigma^2}{n} =  \\frac{n-1}{n} \\sigma^2,\n    \\end{align*} where we used the fact that Var[\\overline Y] = \\sigma^2/n.\nThe sample variance is downward biased: \\begin{align*}\n        Bias[\\widehat \\sigma_Y^2] = E[\\widehat \\sigma_Y^2] - \\sigma^2 = \\frac{n-1}{n} \\sigma^2 - \\sigma^2 = -\\frac{\\sigma^2}{n}.\n    \\end{align*}\nOn the other hand, the adjusted sample variance is unbiased:\n\\begin{align*}\n        Bias[s_Y^2] = E[s_Y^2] - \\sigma^2 = \\frac{n}{n-1}E[\\widehat \\sigma_Y^2] - \\sigma^2 = \\sigma^2 - \\sigma^2 = 0\n    \\end{align*}\nThe variance of the sample variance can be computed as \n  Var[\\widehat \\sigma_Y^2] = \\frac{\\sigma^4}{n} \\Big( kurt - \\frac{n-3}{n-1} \\Big) \\frac{(n-1)^2}{n^2},\n while the variance of the adjusted sample variance is \n  Var[s_Y^2] = \\frac{\\sigma^4}{n} \\Big( kurt - \\frac{n-3}{n-1} \\Big).\n As long as the kurtosis of the underlying distribution is finite, the sufficient conditions for consistency are satisfied as the bias and variance tend to zero as n \\to \\infty. The adjusted sample variance is unbiased for any n. The sample variance is biased for fixed n but asymptotically unbiased as the bias tends to zero for large n. The sample variance and the adjusted sample variance are consistent for the variance if the sample is i.i.d. and the distribution is not heavy-tailed.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#bias-variance-tradeoff",
    "href": "stat4_expectation.html#bias-variance-tradeoff",
    "title": "6  Expectated value",
    "section": "6.12 Bias-variance tradeoff",
    "text": "6.12 Bias-variance tradeoff\nFrom a bias perspective, adjusted sample variance s_Y^2 is preferred over \\widehat \\sigma^2_Y because s_Y^2 is unbiased. However, from a variance perspective, \\widehat \\sigma^2_Y is preferred due to its smaller variance. Traditionally, the emphasis on unbiasedness has led to a preference for \\widehat \\sigma^2_Y, even at the cost of a higher variance.\nA more modern approach balances bias and variance, known as the bias-variance tradeoff, by selecting an estimator that minimizes the mean squared error (MSE): \n  MSE(\\widehat \\theta) = E[(\\widehat \\theta - \\theta)^2] = Var[\\widehat \\theta] + Bias[\\widehat \\theta]^2.\n For the variance estimators, the MSEs are \n  MSE[\\widehat \\sigma_Y^2] = Var[\\widehat \\sigma_Y^2] + Bias[\\widehat \\sigma_Y^2]^2 = \\frac{\\sigma^4}{n} \\bigg[ \\Big( kurt - \\frac{n-3}{n-1} \\Big) \\frac{(n-1)^2}{n^2} + \\frac{1}{n} \\bigg]\n and \n  MSE[s_Y^2] = Var[s_Y^2] = \\frac{\\sigma^4}{n} \\Big( kurt - \\frac{n-3}{n-1} \\Big).\n Since s_Y^2 is unbiased, its MSE equals its variance.\nIt is not possible to universally determine which estimator has a lower MSE because this depends on the population kurtosis (kurt) of the underlying distribution. However, it can be shown that for all distributions with kurt \\geq 1.5, the relation MSE[s_Y^2] &gt; MSE[\\widehat \\sigma_Y^2] holds, which implies that \\widehat \\sigma_Y^2 is preferred based on the bias-variance tradeoff for all moderately tailed distributions.\nTo give an indication of typical kurtosis values:\n\nSymmetric Bernoulli distribution with P(Y=0) = P(Y=1) = 0.5: kurtosis of 1 (light-tailed).\nUniform distribution (see Equation 6.3): kurtosis of 1.8 (moderately light-tailed).\nNormal distribution: kurtosis of 3 (moderately tailed).\nt_5 distribution: kurtosis of 9 (moderately heavy-tailed).\nt_4 distribution: infinite kurtosis (heavy-tailed).\n\nTherefore, according to the bias-variance tradeoff, the adjusted sample variance s_Y^2 is preferred only for extremely light-tailed distributions, while \\widehat \\sigma_Y^2 is preferred in cases with moderate or higher kurtosis.\nIn practice, especially with larger samples, the difference between s_Y^2 and \\widehat \\sigma_Y^2 becomes negligible, and either estimator is generally acceptable. Therefore, the discussion about a better variance estimator is a bit nitpicky and not of much practical relevance.\nHowever, for instance in high-dimensional regression problems with near multicollinearity (k \\approx n), the bias-variance tradeoff is crucial. In such cases, biased but low-variance estimators like ridge or lasso (shrinkage estimators) are often preferred over ordinary least squares (OLS).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat4_expectation.html#r-codes",
    "href": "stat4_expectation.html#r-codes",
    "title": "6  Expectated value",
    "section": "6.13 R-codes",
    "text": "6.13 R-codes\nstatistics-sec05.R",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expectated value</span>"
    ]
  },
  {
    "objectID": "stat5_conditional.html",
    "href": "stat5_conditional.html",
    "title": "7  Conditional expectation",
    "section": "",
    "text": "7.1 Conditional mean\nFor continuous Y with conditional density f_{Y|\\boldsymbol Z = \\boldsymbol b}(a), we have \\text{d}F_{Y|\\boldsymbol Z = \\boldsymbol b}(a) = f_{Y|\\boldsymbol Z = \\boldsymbol b}(a) \\ \\text{d}a, and the conditional expectation is \n    E[Y | Z= \\boldsymbol b] = \\int_{-\\infty}^\\infty a f_{Y|\\boldsymbol Z = \\boldsymbol b}(a)\\ \\text{d}a.\n Similarly, for discrete Y with support \\mathcal Y and conditional PMF \\pi_{Y|\\boldsymbol Z = \\boldsymbol b}(a), we have \n    E[Y | Z= \\boldsymbol b] = \\sum_{u \\in \\mathcal Y} u \\pi_{Y|\\boldsymbol Z = \\boldsymbol b}(u).\nThe conditional expectation is a function of \\boldsymbol b, which is a specific value of \\boldsymbol Z that we condition on. Therefore, we call it the conditional expectation function: \n  m(\\boldsymbol b) = E[Y | Z= \\boldsymbol b].\nSuppose the conditional expectation of wage given experience level b is: \n  m(b) = E[wage | exper = b] = 14.5 + 0.9 b - 0.017 b^2.\n For example, with 10 years of experience: \nm(10) = E[wage | exper = 10] = 21.8.\nHere, m(b) assigns a specific real number to each fixed value of b; it is a deterministic function derived from the joint distribution of wage and experience.\nHowever, if we treat experience as a random variable, the conditional expectation becomes: \\begin{align*}\n     m(exper) = E[wage | exper] = 14.5 + 0.9 exper - 0.017 exper^2.\n\\end{align*} Now, m(exper) is a function of the random variable experexper and is itself a random variable.\nIn general:\nThis distinction highlights that the conditional expectation can be either a specific number, i.e. E[Y | \\boldsymbol Z=\\boldsymbol b], or a random variable, i.e., E[Y | \\boldsymbol Z], depending on whether the condition is fixed or random.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional expectation</span>"
    ]
  },
  {
    "objectID": "stat5_conditional.html#conditional-mean",
    "href": "stat5_conditional.html#conditional-mean",
    "title": "7  Conditional expectation",
    "section": "",
    "text": "Conditional expectation\nThe conditional expectation or conditional mean of Y given \\boldsymbol  Z= \\boldsymbol b is the expected value of the distribution F_{Y|\\boldsymbol Z=\\boldsymbol b}: \n  E[Y | \\boldsymbol  Z= \\boldsymbol b] = \\int_{-\\infty}^\\infty a \\ \\text{d}F_{Y|\\boldsymbol Z = \\boldsymbol b}(a).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) CEF wage given experience\n\n\n\n\n\n\n\n\n\n\n\n(b) CEF wage given education\n\n\n\n\n\n\n\nFigure 7.1: Conditional expectation functions. The x-axis represents b.\n\n\n\n\n\n\n\n\nThe conditional expectation given a specific value b is: \n    m(\\boldsymbol b) = E[Y | \\boldsymbol Z=\\boldsymbol b],\n which is deterministic.\nThe conditional expectation given the random variable Z is: \nm(\\boldsymbol Z) = E[Y | \\boldsymbol Z],\n\nwhich is a random variable because it depends on the random vector \\boldsymbol Z.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional expectation</span>"
    ]
  },
  {
    "objectID": "stat5_conditional.html#rules-of-calculation",
    "href": "stat5_conditional.html#rules-of-calculation",
    "title": "7  Conditional expectation",
    "section": "7.2 Rules of calculation",
    "text": "7.2 Rules of calculation\nLet Y be a random variable and \\boldsymbol{Z} a random vector. The rules of calculation rules below are fundamental tools for working with conditional expectations:\n\n(i) Law of Iterated Expectations (LIE):\n\nE[E[Y | \\boldsymbol{Z}]] = E[Y].\n\nIntuition: The LIE tells us that if we first compute the expected value of Y given each possible outcome of \\boldsymbol{Z}, and then average those expected values over all possible values of \\boldsymbol{Z}, we end up with the overall expected value of Y. It’s like calculating the average outcome across all scenarios by considering each scenario’s average separately.\nMore generally, for any two random vectors \\boldsymbol{Z} and \\boldsymbol{Z}^*:\n\nE[E[Y | \\boldsymbol{Z}, \\boldsymbol{Z}^*] | \\boldsymbol{Z}] = E[Y | \\boldsymbol{Z}].\n\nIntuition: Even if we condition on additional information \\boldsymbol{Z}^*, averaging over \\boldsymbol{Z}^* while keeping \\boldsymbol{Z} fixed brings us back to the conditional expectation given \\boldsymbol{Z} alone.\n\n(ii) Conditioning Theorem (CT):\nFor any function g(\\boldsymbol{Z}):\n\nE[g(\\boldsymbol{Z}) \\, Y | \\boldsymbol{Z}] = g(\\boldsymbol{Z}) \\, E[Y | \\boldsymbol{Z}].\n\nIntuition: Once we know \\boldsymbol{Z}, the function g(\\boldsymbol{Z}) becomes a known quantity. Therefore, when computing the conditional expectation given \\boldsymbol{Z}, we can treat g(\\boldsymbol{Z}) as a constant and factor it out.\n\n(iii) Independence Rule (IR):\nIf Y and \\boldsymbol{Z} are independent, then:\n\nE[Y | \\boldsymbol{Z}] = E[Y].\n\nIntuition: Independence means that Y and \\boldsymbol{Z} do not influence each other. Knowing the value of \\boldsymbol{Z} gives us no additional information about Y. Therefore, the expected value of Y remains the same regardless of the value of \\boldsymbol{Z}, so the conditional expectation equals the unconditional expectation.\nAnother way to see this is the fact that, if Y and Z are independent, then \n  F_{Y|Z=b}(a) = F_{Y}(a) \\quad \\text{for all} \\ a \\ \\text{and} \\ b.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional expectation</span>"
    ]
  },
  {
    "objectID": "stat5_conditional.html#expectation-of-bivariate-random-variables",
    "href": "stat5_conditional.html#expectation-of-bivariate-random-variables",
    "title": "7  Conditional expectation",
    "section": "7.3 Expectation of bivariate random variables",
    "text": "7.3 Expectation of bivariate random variables\nWe often are interested in expected values of functions involving two random variables, such as the cross-moment E[YZ] for variables Y and Z.\nIf F(a,b) is the joint CDF of (Y,Z), then the cross-moment is defined as: \n  E[YZ] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty ab \\ \\text{d}F(a,b).\n\\tag{7.1} If Y and Z are continuous and F(a,b) is differentiable, the joint probability density function (PDF) of (Y,Z): \n    f(a,b) = \\frac{\\partial^2}{\\partial a \\partial b} F(a,b).\n This allows us to write the differential of the CDF as \n   \\text{d}F(a,b) = f(a,b) \\ \\text{d} a \\ \\text{d}b,\n and the cross-moment becomes: \nE[YZ] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty ab \\ \\text{d}F(a,b) =  \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty ab f(a,b) \\ \\text{d} a \\ \\text{d}b.\n In the wage and experience example, we have the following joint CDF and joint PDF:\n\n\n\n\n\n\nFigure 7.2: Joint CDF of wage and experience\n\n\n\n\n\n\n\n\n\nFigure 7.3: Joint PDF of wage and experience\n\n\n\nIf Y and Z are discrete with joint PMF \\pi(a,b) and support \\mathcal Y, the cross moment is \nE[YZ] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty ab \\ \\text{d}F(a,b) = \\sum_{a \\in \\mathcal Y} \\sum_{b \\in \\mathcal Y} ab \\ \\pi(a,b).\n If one variable is discrete and the other is continuous, the expectation involves a mixture of summation and integration.\nIn general, the expected value of any real valued function g(Y,Z) is given by \n  E[g(X,Y)] = \\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty g(a,b) \\ \\text{d}F(a,b).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional expectation</span>"
    ]
  },
  {
    "objectID": "stat5_conditional.html#covariance-and-correlation",
    "href": "stat5_conditional.html#covariance-and-correlation",
    "title": "7  Conditional expectation",
    "section": "7.4 Covariance and correlation",
    "text": "7.4 Covariance and correlation\nThe covariance of Y and Z is defined as:\n\n   Cov(Y,Z) = E[(Y- E[Y])(Z-E[Z])] = E[YZ] - E[Y]E[Z].\n The covariance of Y with itself is the variance: \n  Cov(Y,Y) = Var[Y].\n The variance of the sum of two random variables depends on the covariance: \n  Var[Y+Z] = Var[Y] + 2 Cov(Y,Z) + Var[Z]\n The correlation of Y and Z is \n  Corr(Y,Z) = \\frac{Cov(Y,Z)}{sd(Y) sd(Z)}\n where sd(Y) and sd(Z) are the standard deviations of Y and Z, respectively.\n\nUncorrelated\nY and Z are uncorrelated if Corr(Y,Z) = 0, or, equivalently, if Cov(Y,Z) = 0.\n\n\n\nIf Y and Z are uncorrelated, then: \\begin{align*}\n        E[YZ] &= E[Y] E[Z] \\\\\n        Var[Y+Z] &= Var[Y] + Var[Z]\n\\end{align*}\nIf Y and Z are independent and have finite second moments, they are uncorrelated. However, the reverse is not necessarily true; uncorrelated variables are not always independent.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional expectation</span>"
    ]
  },
  {
    "objectID": "stat5_conditional.html#expectations-for-random-vectors",
    "href": "stat5_conditional.html#expectations-for-random-vectors",
    "title": "7  Conditional expectation",
    "section": "7.5 Expectations for random vectors",
    "text": "7.5 Expectations for random vectors\nThese concepts generalize to any k-dimensional random vector \\boldsymbol Z = (Z_1, \\ldots, Z_k).\nThe expectation vector of \\boldsymbol Z is: \n        E[\\boldsymbol Z] = \\begin{pmatrix} E[Z_1] \\\\  \\vdots \\\\ E[Z_k] \\end{pmatrix}.\n The covariance matrix of \\boldsymbol Z is: \\begin{align*}\nVar[\\boldsymbol Z] &= E[(\\boldsymbol Z-E[\\boldsymbol Z])(\\boldsymbol Z-E[\\boldsymbol Z])'] \\\\\n      &= \\begin{pmatrix}\n            Var[Z_1] & Cov(Z_1, Z_2) & \\ldots & Cov(X_1, Z_k) \\\\\n            Cov(Z_2, Z_1) & Var[Z_2] & \\ldots & Cov(Z_2, Z_k) \\\\\n            \\vdots & \\vdots & \\ddots & \\vdots \\\\\n            Cov(Z_k, Z_1) & Cov(Z_k, Z_2) & \\ldots & Var[Z_k]\n        \\end{pmatrix}\n\\end{align*}\nFor any random vector \\boldsymbol Z, the covariance matrix Var[\\boldsymbol Z] is symmetric and positive semi-definite.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional expectation</span>"
    ]
  },
  {
    "objectID": "stat5_conditional.html#r-codes",
    "href": "stat5_conditional.html#r-codes",
    "title": "7  Conditional expectation",
    "section": "7.6 R-codes",
    "text": "7.6 R-codes\nstatistics-sec07.R",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Conditional expectation</span>"
    ]
  },
  {
    "objectID": "part1_distribution.html#events-and-probabilities",
    "href": "part1_distribution.html#events-and-probabilities",
    "title": "\n1  Distribution\n",
    "section": "\n1.3 Events and Probabilities",
    "text": "1.3 Events and Probabilities\nTo quantify the uncertainty in random variables, we need to assign probabilities to different possible outcomes or sets of outcomes. This is where events and probability functions come into play.\nAn event of a random variable Y is a specific subset of the real line. Any real number defines an event (elementary event), and any open, half-open, or closed interval represents an event as well.\nLet’s define some specific events:\n\nElementary events: \n  A_1 = \\{Y=0\\}, \\quad A_2 = \\{Y=1\\}, \\quad A_3 = \\{Y=2.5\\}\n\nHalf-open events: \\begin{align*}\nA_4 &= \\{Y \\geq 0\\} = \\{ Y \\in [0,\\infty) \\} \\\\\nA_5 &= \\{ -1 \\leq Y &lt; 1 \\} = \\{ Y \\in [-1,1) \\}\n\\end{align*}\n\nThe probability function P assigns values between 0 and 1 to events. For a fair coin toss (where Y=1 represents heads and Y=0 represents tails), it is natural to assign the following probabilities: \n  P(A_1) = P(Y=0) = 0.5, \\quad P(A_2) = P(Y=1) = 0.5\n\nBy definition, the coin variable will never take the value 2.5, so we assign \n  P(A_3) = P(Y=2.5) = 0\n\nTo assign probabilities to interval events, we check whether the elementary events \\{Y=0\\} and/or \\{Y=1\\} are subsets of the event of interest:\n\nIf both \\{Y=0\\} and \\{Y=1\\} are contained in the event of interest, the probability is 1\nIf only one of them is contained, the probability is 0.5\nIf neither is contained, the probability is 0\n\nFor our examples: \n  P(A_4) = P(Y \\geq 0) = 1, \\quad P(A_5) = P(-1 \\leq Y &lt; 1) = 0.5\n\nEvery event has a complementary event (denoted with superscript c), which consists of all outcomes not in the original event. For any pair of events, we can also take the union (denoted by \\cup) and intersection (denoted by \\cap). Let’s define further events:\n\nComplement (all outcomes not in the original event): \nA_6 = A_4^c = \\{Y \\geq 0\\}^c = \\{Y &lt; 0\\} = \\{Y \\in (-\\infty, 0)\\}\n\nUnion (outcomes in either event): \nA_7 = A_1 \\cup A_6 = \\{Y=0\\} \\cup \\{Y&lt; 0\\} = \\{Y \\leq 0\\}\n\nIntersection (outcomes in both events): \nA_8 = A_4 \\cap A_5 = \\{Y \\geq 0\\} \\cap \\{-1 \\leq Y &lt; 1\\} = \\{0 \\leq Y &lt; 1\\}\n\nCombinations of multiple events: \n  A_9 = A_1 \\cup A_2 \\cup A_3 \\cup A_5 \\cup A_6 \\cup A_7 \\cup A_8 = \\{Y \\in (-\\infty, 1] \\cup \\{2.5\\}\\}\n\nCertain event (contains all possible outcomes): \nA_{10} = A_9 \\cup A_9^c = \\{Y \\in (-\\infty, \\infty)\\} = \\{Y \\in \\mathbb{R}\\}\n\nEmpty event (contains no outcomes): \nA_{11} = A_{10}^c = \\{Y \\notin \\mathbb{R}\\} = \\{\\}\n\n\nFor the coin toss experiment, we can verify the probabilities of all these events:\n\n\nP(A_1) = 0.5 (probability of tails)\n\nP(A_2) = 0.5 (probability of heads)\n\nP(A_3) = 0 (coin never shows 2.5)\n\nP(A_4) = 1 (coin always shows a non-negative value)\n\nP(A_5) = 0.5 (only tails falls in this interval)\n\nP(A_6) = 0 (coin never shows a negative value)\n\nP(A_7) = 0.5 (same as probability of tails)\n\nP(A_8) = 0.5 (contains only tails)\n\nP(A_9) = 1 (contains all possible coin outcomes)\n\nP(A_{10}) = 1 (the certain event always occurs)\n\nP(A_{11}) = 0 (the empty event never occurs)\n\nTo illustrate how events and probabilities apply in other contexts, consider our education level example. If Y represents years of schooling with possible values \\{4, 10, 12, 13, 14, 16, 18, 21\\}, we might define the event B = \\{Y \\geq 16\\} representing “has at least a Bachelor’s degree.” The probability P(B) would then represent the proportion of the population with at least a Bachelor’s degree.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribution</span>"
    ]
  },
  {
    "objectID": "part1_distribution.html#probability-function",
    "href": "part1_distribution.html#probability-function",
    "title": "\n1  Distribution\n",
    "section": "\n1.4 Probability Function",
    "text": "1.4 Probability Function\nNow that we hve defined events, we need a formal way to assign probabilities to them consistently. The probability function P assigns probabilities to events within the Borel sigma-algebra (denoted as \\mathcal B), which contains all events we would ever need to compute probabilities for in practice. This includes our previously mentioned events A_1, \\ldots, A_{11}, any interval of the form \\{ Y \\in (a,b) \\} with a, b \\in \\mathbb{R}, and all possible unions, intersections, and complements of these events.\nTwo events A and B are disjoint if A \\cap B = \\{\\}, meaning they have no common outcomes. For example, A_1 = \\{Y=0\\} and A_2 = \\{Y=1\\} are disjoint (a coin cannot show both heads and tails simultaneously), while A_1 and A_4 = \\{Y \\geq 0\\} are not disjoint since A_1 \\cap A_4 = \\{Y=0\\}.\nA probability function P must satisfy certain fundamental rules (axioms) to ensure a well-defined probability framework:\n\nBasic Rules of Probability\nFundamental Axioms:\n\n\nP(A) \\geq 0 for any event A (non-negativity)\n\nP(Y \\in \\mathbb R) = 1 for the certain event (normalization)\n\nP(A \\cup B) = P(A) + P(B) if A and B are disjoint (additivity)\n\nImplied Properties:\n\n\nP(Y \\notin \\mathbb R) = P(\\{\\}) = 0 for the empty event\n\n0 \\leq P(A) \\leq 1 for any event A\n\n\nP(A) \\leq P(B) if A is a subset of B (monotonicity)\n\nP(A^c) = 1 - P(A) for the complement event of A\n\n\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B) for any events A, B\n\n\n\n\nThe first three properties listed above are known as the axioms of probability, first formalized by Andrey Kolmogorov in 1933. The remaining properties follow as logical consequences of these axioms.\nLet’s consider a practical example: In our education survey, suppose we know the following probabilities:\n\nP(\\text{Primary education}) = 0.1\nP(\\text{Secondary education}) = 0.6\nP(\\text{Tertiary education}) = 0.3\n\nThese events are disjoint (a person cannot simultaneously have exactly primary and exactly secondary education as their highest level), and they cover all possibilities (everyone has some highest level of education). Using the axioms:\n\nEach probability is non-negative (satisfying axiom 1)\nThe sum 0.1 + 0.6 + 0.3 = 1 (satisfying axiom 2)\nThe probability of having either primary or secondary education is P(\\text{Primary or Secondary}) = P(\\text{Primary}) + P(\\text{Secondary}) = 0.1 + 0.6 = 0.7 (using axiom 3 for disjoint events)\n\nFrom the derived properties, we can also calculate that the probability of not having tertiary education is P(\\text{No tertiary}) = 1 - P(\\text{Tertiary}) = 1 - 0.3 = 0.7.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Distribution</span>"
    ]
  }
]